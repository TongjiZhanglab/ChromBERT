{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example for key regulators inference during cell state transition: chromatin accessibility\n",
    "\n",
    "To comprehensively infer key regulators during cell state transitions, it is crucial to integrate analyses of chromatin accessibility and the transcriptome. In this tutorial, we will demonstrate how to use ChromBERT to infer key regulators involved in a specific transdifferentiation process (fibroblast to myoblast) through chromatin accessibility analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]='0'\n",
    "import chrombert\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from torchinfo import summary\n",
    "import subprocess\n",
    "import torch\n",
    "import lightning.pytorch as pl \n",
    "base_dir =  os.path.expanduser(\"~/.cache/chrombert/data\") # set the base directory for storing data default\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess dataset  \n",
    "\n",
    "In this section, we prepare raw chromatin accessibility data, including peak and BigWig files for the cell types involved in transdifferentiation. This tutorial will guide you through formatting the data for use with ChromBERT.  \n",
    "\n",
    "To identify key regulators, we fine-tune ChromBERT to predict log2-transformed chromatin accessibility signal fold changes during transdifferentiation. This process involves preparing the transformed data. Additionally, to analyze the distances between regulator embeddings at upregulated and unchanged loci, we need to prepare and identify data for both types of loci. The preprocessing steps include:  \n",
    "\n",
    "- Collecting peaks involved in transdifferentiation and TSS flank regions as background (extending 10 kb all TSSs).  \n",
    "- Overlapping these regions with the 1 kb regions used in ChromBERT.  \n",
    "- Extracting chromatin accessibility signals from BigWig files for each of these 1 kb regions.  \n",
    "- Calculating log2-transformed chromatin accessibility changes.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "chromatin_accessibility_dir = f'{base_dir}/demo/transdifferentiation/chrom_accessibility'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download the data needed for this tutorial\n",
    "if not os.path.exists(f'{chromatin_accessibility_dir}/fibroblast_ENCFF184KAM_peak.bed'):\n",
    "     cmd = f'wget https://www.encodeproject.org/files/ENCFF184KAM/@@download/ENCFF184KAM.bed.gz -O {chromatin_accessibility_dir}/fibroblast_ENCFF184KAM_peak.bed'\n",
    "     subprocess.run(cmd, shell=True)\n",
    "if not os.path.exists(f'{chromatin_accessibility_dir}/fibroblast_ENCFF361BTT_signal.bigwig'):\n",
    "     cmd = f'wget https://www.encodeproject.org/files/ENCFF361BTT/@@download/ENCFF361BTT.bigWig -O {chromatin_accessibility_dir}/fibroblast_ENCFF361BTT_signal.bigwig'\n",
    "     subprocess.run(cmd, shell=True)\n",
    "if not os.path.exists(f'{chromatin_accessibility_dir}/myoblast_ENCFF647RNC_peak.bed'):\n",
    "     cmd = f'wget https://www.encodeproject.org/files/ENCFF647RNC/@@download/ENCFF647RNC.bed.gz -O {chromatin_accessibility_dir}/myoblast_ENCFF647RNC_peak.bed'\n",
    "     subprocess.run(cmd, shell=True)\n",
    "if not os.path.exists(f'{chromatin_accessibility_dir}/myoblast_ENCFF149ERN_signal.bigwig'):\n",
    "     cmd = f'wget https://www.encodeproject.org/files/ENCFF149ERN/@@download/ENCFF149ERN.bigWig -O {chromatin_accessibility_dir}/myoblast_ENCFF149ERN_signal.bigwig'\n",
    "     subprocess.run(cmd, shell=True)     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prepare merged peaks  \n",
    "\n",
    "Here we merge the peaks for the cell types involved in transdifferentiation to generate a comprehensive region list.  \n",
    "Then, we align the genomic coordinates of these regions with ChromBERT's 1 kb bins."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CompletedProcess(args='bedtools merge -i /home/chenqianqian/.cache/chrombert/data/demo/transdifferentiation/chrom_accessibility/tmp_peak_sorted.bed > /home/chenqianqian/.cache/chrombert/data/demo/transdifferentiation/chrom_accessibility/total_peak.bed', returncode=0)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cmd = f\"cat {chromatin_accessibility_dir}/fibroblast_ENCFF184KAM_peak.bed {chromatin_accessibility_dir}/myoblast_ENCFF647RNC_peak.bed > {chromatin_accessibility_dir}/tmp_peak.bed\"\n",
    "subprocess.run(cmd, shell=True)\n",
    "cmd = f\"sort -k1,1 -k2,2n {chromatin_accessibility_dir}/tmp_peak.bed > {chromatin_accessibility_dir}/tmp_peak_sorted.bed\"\n",
    "subprocess.run(cmd, shell=True)\n",
    "cmd = f\"bedtools merge -i {chromatin_accessibility_dir}/tmp_peak_sorted.bed > {chromatin_accessibility_dir}/total_peak.bed\"\n",
    "subprocess.run(cmd, shell=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(396195,\n",
       "   chrom   start     end  build_region_index\n",
       " 0  chr1  180000  181000                  38\n",
       " 1  chr1  181000  182000                  39\n",
       " 2  chr1  182000  183000                  40\n",
       " 3  chr1  191000  192000                  46\n",
       " 4  chr1  268000  269000                  54)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from chrombert.scripts.chrombert_make_dataset import get_regions,process\n",
    "chrom_regions = get_regions(base_dir,genome='hg38',high_resolution=False) # 1kb\n",
    "total_peak_process = process(f'{chromatin_accessibility_dir}/total_peak.bed',chrom_regions,mode='region')[['chrom','start','end','build_region_index']]\n",
    "len(total_peak_process),total_peak_process.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generate background regions  \n",
    "\n",
    "In this study, we use TSS flank regions (within 10 kb of the transcription start site) as background samples to facilitate the fine-tuning process and identify key regulators."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>chrom</th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>chr19</td>\n",
       "      <td>58343492</td>\n",
       "      <td>58363492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>chr19</td>\n",
       "      <td>58337718</td>\n",
       "      <td>58357718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>chr10</td>\n",
       "      <td>50875675</td>\n",
       "      <td>50895675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>chr12</td>\n",
       "      <td>9106229</td>\n",
       "      <td>9126229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>chr12</td>\n",
       "      <td>9055163</td>\n",
       "      <td>9075163</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   chrom     start       end\n",
       "0  chr19  58343492  58363492\n",
       "1  chr19  58337718  58357718\n",
       "2  chr10  50875675  50895675\n",
       "3  chr12   9106229   9126229\n",
       "4  chr12   9055163   9075163"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gep_df = pd.read_csv(f'{chromatin_accessibility_dir}/../transcriptome/fibroblast_to_myoblast_expression_changes.csv')\n",
    "gep_df_tss_10kb = pd.DataFrame({'chrom':gep_df['chrom'],'start':gep_df['tss']-10000,'end':gep_df['tss']+10000})\n",
    "gep_df_tss_10kb\n",
    "gep_df_tss_10kb.to_csv(f'{chromatin_accessibility_dir}/gep_df_tss_10kb.bed',sep='\\t',index=False,header=None)\n",
    "gep_df_tss_10kb.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(295682,\n",
       "   chrom   start     end  build_region_index\n",
       " 0  chr1  815000  816000                 126\n",
       " 1  chr1  816000  817000                 127\n",
       " 2  chr1  817000  818000                 128\n",
       " 3  chr1  818000  819000                 129\n",
       " 4  chr1  819000  820000                 130)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gep_df_tss_10kb_process = process(f'{chromatin_accessibility_dir}/gep_df_tss_10kb.bed',chrom_regions,mode='region').drop_duplicates(subset='build_region_index')[['chrom','start','end','build_region_index']]\n",
    "len(gep_df_tss_10kb_process),gep_df_tss_10kb_process.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Collect total regions and further process\n",
    "Here we concatenate the total peak and background regions to generate the total region. Then, we extract the chromatin accessibility signals for each region and perform log2 transformation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(614861,\n",
       "   chrom   start     end  build_region_index\n",
       " 0  chr1  180000  181000                  38\n",
       " 1  chr1  181000  182000                  39\n",
       " 2  chr1  182000  183000                  40\n",
       " 3  chr1  191000  192000                  46\n",
       " 4  chr1  268000  269000                  54)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_region_processed = pd.concat([total_peak_process,gep_df_tss_10kb_process],axis=0).drop_duplicates().reset_index(drop=True)\n",
    "total_region_processed.to_csv(f'{chromatin_accessibility_dir}/total_region_processed.csv',index=False)\n",
    "len(total_region_processed),total_region_processed.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the chromatin accessibility signals\n",
    "\n",
    "import bbi  # pip install pybbi\n",
    "def bw_getSignal_bins(\n",
    "    bw, regions:pd.DataFrame,name\n",
    "    ):\n",
    "    regions = regions.copy()\n",
    "    with bbi.open(str(bw)) as bwf:\n",
    "        mtx = bwf.stackup(regions[\"chrom\"],regions[\"start\"],regions[\"end\"], bins=1, missing=0)\n",
    "        mean= bwf.info[\"summary\"][\"mean\"]\n",
    "        mtx = mtx/mean\n",
    "    df_signal = pd.DataFrame(data = mtx, columns = [f'{name}_signal'])\n",
    "    return df_signal\n",
    "\n",
    "fibroblast_signal = bw_getSignal_bins(bw=f'{chromatin_accessibility_dir}/fibroblast_ENCFF361BTT_signal.bigwig',regions=total_region_processed,name='fibroblast')\n",
    "myoblast_signal = bw_getSignal_bins(bw=f'{chromatin_accessibility_dir}/myoblast_ENCFF149ERN_signal.bigwig',regions=total_region_processed,name='myoblast')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>chrom</th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "      <th>build_region_index</th>\n",
       "      <th>label</th>\n",
       "      <th>fibroblast_signal</th>\n",
       "      <th>myoblast_signal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>chr1</td>\n",
       "      <td>180000</td>\n",
       "      <td>181000</td>\n",
       "      <td>38</td>\n",
       "      <td>0.091821</td>\n",
       "      <td>0.066471</td>\n",
       "      <td>0.136553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>chr1</td>\n",
       "      <td>181000</td>\n",
       "      <td>182000</td>\n",
       "      <td>39</td>\n",
       "      <td>0.001996</td>\n",
       "      <td>2.543848</td>\n",
       "      <td>2.548754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>chr1</td>\n",
       "      <td>182000</td>\n",
       "      <td>183000</td>\n",
       "      <td>40</td>\n",
       "      <td>0.142237</td>\n",
       "      <td>0.102401</td>\n",
       "      <td>0.216626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>chr1</td>\n",
       "      <td>191000</td>\n",
       "      <td>192000</td>\n",
       "      <td>46</td>\n",
       "      <td>-0.678009</td>\n",
       "      <td>1.386900</td>\n",
       "      <td>0.491877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>chr1</td>\n",
       "      <td>268000</td>\n",
       "      <td>269000</td>\n",
       "      <td>54</td>\n",
       "      <td>-0.329329</td>\n",
       "      <td>1.324022</td>\n",
       "      <td>0.849704</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  chrom   start     end  build_region_index     label  fibroblast_signal  \\\n",
       "0  chr1  180000  181000                  38  0.091821           0.066471   \n",
       "1  chr1  181000  182000                  39  0.001996           2.543848   \n",
       "2  chr1  182000  183000                  40  0.142237           0.102401   \n",
       "3  chr1  191000  192000                  46 -0.678009           1.386900   \n",
       "4  chr1  268000  269000                  54 -0.329329           1.324022   \n",
       "\n",
       "   myoblast_signal  \n",
       "0         0.136553  \n",
       "1         2.548754  \n",
       "2         0.216626  \n",
       "3         0.491877  \n",
       "4         0.849704  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Prepare the log2-transformed chromatin accessibility signal fold changes data\n",
    "\n",
    "total_region_signal_processed = pd.concat([total_region_processed,fibroblast_signal,myoblast_signal],axis=1)\n",
    "total_region_signal_processed['fold_change'] = np.log2(1+total_region_signal_processed['myoblast_signal']) - np.log2(1+total_region_signal_processed['fibroblast_signal'])\n",
    "total_region_signal_processed\n",
    "chrom_accessibility_df = (\n",
    "    total_region_signal_processed[\n",
    "        ['chrom','start','end','build_region_index','fold_change','fibroblast_signal','myoblast_signal']\n",
    "    ].rename(columns={'fold_change':'label'})\n",
    ")\n",
    "chrom_accessibility_df.to_csv(f'{chromatin_accessibility_dir}/fibroblast_to_myoblast_chrom_accessibility_changes.csv',index=False)\n",
    "chrom_accessibility_df.head() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prepare fine-tuning data  \n",
    "\n",
    "The dataset is split into training, testing, and validation sets in an 8:1:1 ratio.  \n",
    "To make the fine-tuning process simpler and faster, the data is then reduced to match these proportions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>chrom</th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "      <th>build_region_index</th>\n",
       "      <th>label</th>\n",
       "      <th>fibroblast_signal</th>\n",
       "      <th>myoblast_signal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>58450</th>\n",
       "      <td>chr11</td>\n",
       "      <td>16348000</td>\n",
       "      <td>16349000</td>\n",
       "      <td>300336</td>\n",
       "      <td>-0.422661</td>\n",
       "      <td>1.251264</td>\n",
       "      <td>0.679549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81335</th>\n",
       "      <td>chr12</td>\n",
       "      <td>49808000</td>\n",
       "      <td>49809000</td>\n",
       "      <td>422035</td>\n",
       "      <td>1.398294</td>\n",
       "      <td>0.950350</td>\n",
       "      <td>4.140920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>346805</th>\n",
       "      <td>chr7</td>\n",
       "      <td>148855000</td>\n",
       "      <td>148856000</td>\n",
       "      <td>1856383</td>\n",
       "      <td>-0.905614</td>\n",
       "      <td>2.071367</td>\n",
       "      <td>0.639512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35488</th>\n",
       "      <td>chr1</td>\n",
       "      <td>246417000</td>\n",
       "      <td>246418000</td>\n",
       "      <td>182254</td>\n",
       "      <td>-2.684815</td>\n",
       "      <td>27.481988</td>\n",
       "      <td>3.429557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>247095</th>\n",
       "      <td>chr3</td>\n",
       "      <td>132783000</td>\n",
       "      <td>132784000</td>\n",
       "      <td>1302011</td>\n",
       "      <td>3.011465</td>\n",
       "      <td>3.356764</td>\n",
       "      <td>34.132198</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        chrom      start        end  build_region_index     label  \\\n",
       "58450   chr11   16348000   16349000              300336 -0.422661   \n",
       "81335   chr12   49808000   49809000              422035  1.398294   \n",
       "346805   chr7  148855000  148856000             1856383 -0.905614   \n",
       "35488    chr1  246417000  246418000              182254 -2.684815   \n",
       "247095   chr3  132783000  132784000             1302011  3.011465   \n",
       "\n",
       "        fibroblast_signal  myoblast_signal  \n",
       "58450            1.251264         0.679549  \n",
       "81335            0.950350         4.140920  \n",
       "346805           2.071367         0.639512  \n",
       "35488           27.481988         3.429557  \n",
       "247095           3.356764        34.132198  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data = chrom_accessibility_df.sample(frac=0.8,random_state=55)\n",
    "test_data = chrom_accessibility_df.drop(train_data.index).sample(frac=0.5,random_state=55)\n",
    "valid_data = chrom_accessibility_df.drop(train_data.index).drop(test_data.index)\n",
    "\n",
    "train_data_sample = train_data.sample(n=80,random_state=55)\n",
    "test_data_sample = test_data.sample(n=20,random_state=55)\n",
    "valid_data_sample = valid_data.sample(n=20,random_state=55)\n",
    "\n",
    "\n",
    "train_data_sample.to_csv(f'{chromatin_accessibility_dir}/train_sample.csv',index=False)\n",
    "test_data_sample.to_csv(f'{chromatin_accessibility_dir}/test_sample.csv',index=False)\n",
    "valid_data_sample.to_csv(f'{chromatin_accessibility_dir}/valid_sample.csv',index=False)\n",
    "train_data_sample.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### Identification of upregulated and unchanged genomic regions  \n",
    "\n",
    "Genomic regions with a log2-transformed chromatin accessibility difference greater than 2 were classified as upregulated, indicating increased accessibility. Regions with insufficient coverage were excluded. Unchanged regions were identified by selecting the 40,000 loci with the smallest absolute fold changes in chromatin accessibility.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_405465/1160250605.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  covered_region['label_abs'] = np.abs(covered_region['label'])\n"
     ]
    }
   ],
   "source": [
    "chrom_accessibility_df = pd.read_csv(f'{chromatin_accessibility_dir}/fibroblast_to_myoblast_chrom_accessibility_changes.csv')\n",
    "up_data = chrom_accessibility_df[chrom_accessibility_df['label']>2]\n",
    "\n",
    "covered_region = chrom_accessibility_df[(chrom_accessibility_df['fibroblast_signal']>0) & (chrom_accessibility_df['myoblast_signal']>0)]\n",
    "covered_region['label_abs'] = np.abs(covered_region['label'])\n",
    "nochange_data = covered_region.sort_values('label_abs').reset_index(drop=True).iloc[0:40000]\n",
    "\n",
    "\n",
    "up_data_sample = up_data.sample(n=100,random_state=55)\n",
    "nochange_data_sample = nochange_data.sample(n=100,random_state=55)\n",
    "\n",
    "\n",
    "up_data_sample.to_csv(f'{chromatin_accessibility_dir}/up_data_sample.csv',index=False)\n",
    "nochange_data_sample.to_csv(f'{chromatin_accessibility_dir}/nochange_data_sample.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fine-tune  \n",
    "\n",
    "This section provides a tutorial for fine-tuning ChromBERTs to predict genome-wide changes in chromatin accessibility.  \n",
    "The fine-tuning process for chromatin accessibility is similar to the general process:  \n",
    "- **Dataset configuration:** Use the `general` preset dataset configuration.  \n",
    "- **Model instantiation:** Use the `general` preset model configuration.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configure dataset and data module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "update path: hdf5_file = hg38_6k_1kb.hdf5\n",
      "update path: meta_file = config/hg38_6k_meta.json\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DatasetConfig({'hdf5_file': '/home/chenqianqian/.cache/chrombert/data/hg38_6k_1kb.hdf5', 'supervised_file': None, 'kind': 'GeneralDataset', 'meta_file': '/home/chenqianqian/.cache/chrombert/data/config/hg38_6k_meta.json', 'ignore': False, 'ignore_object': None, 'batch_size': 4, 'num_workers': 4, 'shuffle': False, 'pin_memory': True, 'perturbation': False, 'perturbation_object': None, 'perturbation_value': 0, 'prompt_kind': None, 'prompt_regulator': None, 'prompt_regulator_cache_file': None, 'prompt_celltype': None, 'prompt_celltype_cache_file': None, 'prompt_regulator_cache_pin_memory': False, 'prompt_regulator_cache_limit': 3, 'fasta_file': None, 'flank_window': 0})"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use the `general` preset dataset config\n",
    "dataset_config = chrombert.get_preset_dataset_config(\"general\",supervised_file = None, batch_size = 4, num_workers = 4)\n",
    "dataset_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We use the `LitChromBERTFTDataModule` to load the data and facilitate the fine-tuning process.\n",
    "data_module = chrombert.LitChromBERTFTDataModule(\n",
    "    config = dataset_config, \n",
    "    train_params = {'supervised_file': f'{chromatin_accessibility_dir}/train_sample.csv'}, \n",
    "    val_params = {'supervised_file':f'{chromatin_accessibility_dir}/valid_sample.csv'}, \n",
    "    test_params = {'supervised_file':f'{chromatin_accessibility_dir}/test_sample.csv'}\n",
    ")\n",
    "data_module.setup()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configure model and instantiation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "update path: mtx_mask = config/hg38_6k_mask_matrix.tsv\n",
      "update path: pretrain_ckpt = checkpoint/hg38_6k_1kb_pretrain.ckpt\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ChromBERTFTConfig:\n",
       "{\n",
       "    \"genome\": \"hg38\",\n",
       "    \"task\": \"general\",\n",
       "    \"dim_output\": 1,\n",
       "    \"mtx_mask\": \"/home/chenqianqian/.cache/chrombert/data/config/hg38_6k_mask_matrix.tsv\",\n",
       "    \"dropout\": 0.1,\n",
       "    \"pretrain_ckpt\": \"/home/chenqianqian/.cache/chrombert/data/checkpoint/hg38_6k_1kb_pretrain.ckpt\",\n",
       "    \"finetune_ckpt\": null,\n",
       "    \"ignore\": false,\n",
       "    \"ignore_index\": [\n",
       "        null,\n",
       "        null\n",
       "    ],\n",
       "    \"gep_flank_window\": 4,\n",
       "    \"gep_parallel_embedding\": false,\n",
       "    \"gep_gradient_checkpoint\": false,\n",
       "    \"gep_zero_inflation\": false,\n",
       "    \"prompt_kind\": \"cistrome\",\n",
       "    \"prompt_dim_external\": 512,\n",
       "    \"dnabert2_ckpt\": null\n",
       "}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we use `general` preset model config \n",
    "model_config = chrombert.get_preset_model_config(\"general\")\n",
    "model_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "use organisim hg38; max sequence length is 6391\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/shared/chenqianqian/data_copy1/chenqianqian/finetune/test_model/ChromBERT_public_2/chrombert/base/model.py:56: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  ck = torch.load(ckpt_path, map_location=torch.device('cpu'))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "================================================================================\n",
       "Layer (type:depth-idx)                                  Param #\n",
       "================================================================================\n",
       "ChromBERTGeneral                                        --\n",
       "├─ChromBERT: 1-1                                        --\n",
       "│    └─BERTEmbedding: 2-1                               --\n",
       "│    │    └─TokenEmbedding: 3-1                         (7,680)\n",
       "│    │    └─PositionalEmbedding: 3-2                    (4,909,056)\n",
       "│    │    └─Dropout: 3-3                                --\n",
       "│    └─ModuleList: 2-2                                  --\n",
       "│    │    └─EncoderTransformerBlock: 3-4                (6,497,280)\n",
       "│    │    └─EncoderTransformerBlock: 3-5                (6,497,280)\n",
       "│    │    └─EncoderTransformerBlock: 3-6                (6,497,280)\n",
       "│    │    └─EncoderTransformerBlock: 3-7                (6,497,280)\n",
       "│    │    └─EncoderTransformerBlock: 3-8                (6,497,280)\n",
       "│    │    └─EncoderTransformerBlock: 3-9                (6,497,280)\n",
       "│    │    └─EncoderTransformerBlock: 3-10               6,497,280\n",
       "│    │    └─EncoderTransformerBlock: 3-11               6,497,280\n",
       "├─GeneralHeader: 1-2                                    --\n",
       "│    └─CistromeEmbeddingManager: 2-3                    --\n",
       "│    └─Conv2d: 2-4                                      769\n",
       "│    └─ReLU: 2-5                                        --\n",
       "│    └─ResidualBlock: 2-6                               --\n",
       "│    │    └─Linear: 3-12                                1,099,776\n",
       "│    │    └─Linear: 3-13                                1,049,600\n",
       "│    │    └─LayerNorm: 3-14                             2,048\n",
       "│    │    └─Linear: 3-15                                1,099,776\n",
       "│    │    └─Dropout: 3-16                               --\n",
       "│    └─ResidualBlock: 2-7                               --\n",
       "│    │    └─Linear: 3-17                                787,200\n",
       "│    │    └─Linear: 3-18                                590,592\n",
       "│    │    └─LayerNorm: 3-19                             1,536\n",
       "│    │    └─Linear: 3-20                                787,200\n",
       "│    │    └─Dropout: 3-21                               --\n",
       "│    └─ResidualBlock: 2-8                               --\n",
       "│    │    └─Linear: 3-22                                196,864\n",
       "│    │    └─Linear: 3-23                                65,792\n",
       "│    │    └─LayerNorm: 3-24                             512\n",
       "│    │    └─Linear: 3-25                                196,864\n",
       "│    │    └─Dropout: 3-26                               --\n",
       "│    └─Linear: 2-9                                      257\n",
       "================================================================================\n",
       "Total params: 62,773,762\n",
       "Trainable params: 18,873,346\n",
       "Non-trainable params: 43,900,416\n",
       "================================================================================"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = model_config.init_model()\n",
    "model.freeze_pretrain(2) ### freeze chrombert 6 transformer blocks during fine-tuning \n",
    "summary(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configure training parameters and fine-tune  \n",
    "\n",
    "The model is fine-tuned using PyTorch Lightning with a straightforward parameter configuration. To save time, fine-tuning is performed on a smaller dataset.  \n",
    "\n",
    "*Note:* Due to the stochastic nature of the tuning process, results may vary. For improved performance, consider increasing the number of epochs and expanding the dataset size.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/chenqianqian/.conda/envs/flash23_torch20/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: Metric `SpearmanCorrcoef` will save all targets and predictions in the buffer. For large datasets, this may lead to large memory footprint.\n",
      "  warnings.warn(*args, **kwargs)  # noqa: B028\n"
     ]
    }
   ],
   "source": [
    "train_config = chrombert.finetune.TrainConfig(kind='regression',        \n",
    "                                              loss='rmse',\n",
    "                                              max_epochs=2,\n",
    "                                              accumulate_grad_batches=2,\n",
    "                                              val_check_interval=2,\n",
    "                                              limit_val_batches=10,\n",
    "                                              tag='chrom_accessibility')\n",
    "train_config\n",
    "train_module = train_config.init_pl_module(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using bfloat16 Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "You are using a CUDA device ('NVIDIA A100-PCIE-40GB') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "Missing logger folder: lightning_logs/chrom_accessibility\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "\n",
      "  | Name  | Type             | Params | Mode \n",
      "---------------------------------------------------\n",
      "0 | model | ChromBERTGeneral | 62.8 M | train\n",
      "---------------------------------------------------\n",
      "18.9 M    Trainable params\n",
      "43.9 M    Non-trainable params\n",
      "62.8 M    Total params\n",
      "251.095   Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "30673cba6f9a4c808423bda3092876b3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/chenqianqian/.conda/envs/flash23_torch20/lib/python3.9/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:475: Your `val_dataloader`'s sampler has shuffling enabled, it is strongly recommended that you turn shuffling off for val/test dataloaders.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6e59ea7736aa439791b4e6ede1dc0cf4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9482e0d7ecc94ea6868dc7745b39673b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0f184988380f426a9c05ee0d5c8981a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "945612f7ebb24912a5359123b191bfd6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d9dd2004b4104ccdbf2b74436efa3471",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae7a578c67784bcc943b40464458e29d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cdf503e306124ecdb5888e739495f3ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "11be99b5b8ad41f99f39dc9264b98b0e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e5489fa68595412f92a367dcfdf9961e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5902257e923245709976d6a28bbd128b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fbb1e045175f468688fc859b564c5fae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b7c0b73288db4b17839c78dfab49f55b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a3ec8946a2124e93a1d07f6503e2d00b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ed42f602f60d40409a02f48312a79d91",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1705af9e9bde4f558e688616a6525bba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b1c4f20a4cc04e5484c2f8baad8e7367",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4325f7b06c644de4adb83e1ec0e104c0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f7a520c683714489b432fc19b8a237f1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "92fabfb71861492ebb192b70f4351acb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f1cc6ae9383f4c45847d61d3266d318c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b2def4dbc2f34649a500c3b7983f2e94",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=2` reached.\n"
     ]
    }
   ],
   "source": [
    "callback_ckpt = pl.callbacks.ModelCheckpoint(monitor = f\"{train_config.tag}_validation/{train_config.loss}\", mode = \"min\")\n",
    "trainer = pl.Trainer(\n",
    "    max_epochs=train_config.max_epochs,\n",
    "    log_every_n_steps=1, \n",
    "    limit_val_batches = train_config.limit_val_batches,\n",
    "    val_check_interval = train_config.val_check_interval,\n",
    "    accelerator=\"gpu\", \n",
    "    accumulate_grad_batches= train_config.accumulate_grad_batches, \n",
    "    fast_dev_run=False, \n",
    "    precision=\"bf16-mixed\",\n",
    "    strategy=\"auto\",\n",
    "    callbacks=[\n",
    "        pl.callbacks.LearningRateMonitor(),\n",
    "        callback_ckpt,   \n",
    "    ],\n",
    "    logger=pl.loggers.TensorBoardLogger(\"lightning_logs\", name='chrom_accessibility'),\n",
    "    )\n",
    "trainer.fit(train_module,data_module)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Evaluate the fine-tuned model  \n",
    "\n",
    "ChromBERT has been successfully fine-tuned! You can evaluate the model directly using `pl_module.model`. However, note that due to flash-attention settings, the dropout probability cannot be adjusted by `model.eval()`, which may introduce some randomness to the output.  \n",
    "\n",
    "So, to ensure consistent results,it's suggested to save the fine-tuned checkpoint and reload it into the original model configuration for accurate evaluation.  \n",
    "\n",
    "In addition, we use only downsampled test data for evaluation in this tutorial to save time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate the model fine-tuned with limited data\n",
    "\n",
    "We first load the fine-tuned model and evaluate it on the downsampled test data here.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "update path: mtx_mask = config/hg38_6k_mask_matrix.tsv\n",
      "update path: pretrain_ckpt = checkpoint/hg38_6k_1kb_pretrain.ckpt\n",
      "use organisim hg38; max sequence length is 6391\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/shared/chenqianqian/data_copy1/chenqianqian/finetune/test_model/ChromBERT_public_2/chrombert/base/model.py:56: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  ck = torch.load(ckpt_path, map_location=torch.device('cpu'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading checkpoint from /shared/chenqianqian/data_copy1/chenqianqian/finetune/test_model/ChromBERT_public_2/examples/tutorials/lightning_logs/chrom_accessibility/version_0/checkpoints/epoch=1-step=12.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/shared/chenqianqian/data_copy1/chenqianqian/finetune/test_model/ChromBERT_public_2/chrombert/finetune/model/basic_model.py:49: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  new_state = torch.load(ckpt)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading from pl module, remove prefix 'model.'\n",
      "Loaded 110/110 parameters\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "chrom_accessibility_ft_ckpt = os.path.abspath(glob.glob('./lightning_logs/chrom_accessibility/version_*/checkpoints/*.ckpt')[0])\n",
    "chrom_accessibility_ft_ckpt\n",
    "model_config = chrombert.get_preset_model_config(\"general\")\n",
    "ft_model = model_config.init_model(finetune_ckpt = chrom_accessibility_ft_ckpt,dropout=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:01<00:00,  2.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'pearsonr': tensor(0.1227), 'spearmanr': tensor(0.2571), 'mse': tensor(0.7629), 'mae': tensor(0.5203), 'r2': tensor(-0.0613)}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "/home/chenqianqian/.conda/envs/flash23_torch20/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: Metric `SpearmanCorrcoef` will save all targets and predictions in the buffer. For large datasets, this may lead to large memory footprint.\n",
      "  warnings.warn(*args, **kwargs)  # noqa: B028\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "import torchmetrics as tm\n",
    "dl = data_module.test_dataloader()\n",
    "ft_model = ft_model.cuda().eval()\n",
    "with torch.no_grad():\n",
    "    y_preds = []\n",
    "    y_labels = []\n",
    "    for batch in tqdm(dl,total=len(dl)):\n",
    "        for k in batch:\n",
    "            if isinstance(batch[k], torch.Tensor):\n",
    "                batch[k] = batch[k].cuda()\n",
    "        y_pred = ft_model(batch).cpu()\n",
    "        y_label = batch['label'].cpu()\n",
    "        y_preds.append(y_pred)\n",
    "        y_labels.append(y_label)\n",
    "    y_preds = torch.cat(y_preds)\n",
    "    y_labels = torch.cat(y_labels)\n",
    "predicts = y_preds.view(-1)\n",
    "labels = y_labels.view(-1)\n",
    "metrics_pearsonr = tm.PearsonCorrCoef()\n",
    "metrics_spearmanr = tm.SpearmanCorrCoef()\n",
    "metrics_mse = tm.MeanSquaredError()\n",
    "metrics_mae = tm.MeanAbsoluteError()\n",
    "metrics_r2 = tm.R2Score()\n",
    "score_pearsonr = metrics_pearsonr(predicts, labels)\n",
    "score_spearmanr = metrics_spearmanr(predicts, labels)\n",
    "score_mse = metrics_mse(predicts, labels)\n",
    "score_mae = metrics_mae(predicts, labels)\n",
    "score_r2 = metrics_r2(predicts, labels)\n",
    "scores = {\n",
    "    \"pearsonr\": score_pearsonr,\n",
    "    \"spearmanr\": score_spearmanr,\n",
    "    \"mse\": score_mse,\n",
    "    \"mae\": score_mae,\n",
    "    \"r2\": score_r2,\n",
    "    }\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performance of the Fine-Tuned Model  \n",
    "\n",
    "The model fine-tuned with limited data demonstrated suboptimal performance during evaluation. To address this, we provided a checkpoint fine-tuned on the entire dataset and will evaluate its performance here.  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "update path: mtx_mask = config/hg38_6k_mask_matrix.tsv\n",
      "update path: pretrain_ckpt = checkpoint/hg38_6k_1kb_pretrain.ckpt\n",
      "use organisim hg38; max sequence length is 6391\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/shared/chenqianqian/data_copy1/chenqianqian/finetune/test_model/ChromBERT_public_2/chrombert/base/model.py:56: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  ck = torch.load(ckpt_path, map_location=torch.device('cpu'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading checkpoint from /home/chenqianqian/.cache/chrombert/data/demo/transdifferentiation/chrom_accessibility/chrom_accessibility_fibroblast_to_myoblast.ckpt\n",
      "Loading from pl module, remove prefix 'model.'\n",
      "Loaded 110/110 parameters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/shared/chenqianqian/data_copy1/chenqianqian/finetune/test_model/ChromBERT_public_2/chrombert/finetune/model/basic_model.py:49: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  new_state = torch.load(ckpt)\n"
     ]
    }
   ],
   "source": [
    "chrom_accessibility_ft_ckpt = f'{chromatin_accessibility_dir}/chrom_accessibility_fibroblast_to_myoblast.ckpt'\n",
    "model_config = chrombert.get_preset_model_config(\"general\")\n",
    "ft_model = model_config.init_model(finetune_ckpt = chrom_accessibility_ft_ckpt,dropout=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:01<00:00,  2.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'pearsonr': tensor(0.9576), 'spearmanr': tensor(0.8451), 'mse': tensor(0.0629), 'mae': tensor(0.2033), 'r2': tensor(0.9125)}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "/home/chenqianqian/.conda/envs/flash23_torch20/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: Metric `SpearmanCorrcoef` will save all targets and predictions in the buffer. For large datasets, this may lead to large memory footprint.\n",
      "  warnings.warn(*args, **kwargs)  # noqa: B028\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "import torchmetrics as tm\n",
    "dl = data_module.test_dataloader()\n",
    "ft_model = ft_model.cuda().eval()\n",
    "with torch.no_grad():\n",
    "    y_preds = []\n",
    "    y_labels = []\n",
    "    for batch in tqdm(dl,total=len(dl)):\n",
    "        for k in batch:\n",
    "            if isinstance(batch[k], torch.Tensor):\n",
    "                batch[k] = batch[k].cuda()\n",
    "        y_pred = ft_model(batch).cpu()\n",
    "        y_label = batch['label'].cpu()\n",
    "        y_preds.append(y_pred)\n",
    "        y_labels.append(y_label)\n",
    "    y_preds = torch.cat(y_preds)\n",
    "    y_labels = torch.cat(y_labels)\n",
    "predicts = y_preds.view(-1)\n",
    "labels = y_labels.view(-1)\n",
    "metrics_pearsonr = tm.PearsonCorrCoef()\n",
    "metrics_spearmanr = tm.SpearmanCorrCoef()\n",
    "metrics_mse = tm.MeanSquaredError()\n",
    "metrics_mae = tm.MeanAbsoluteError()\n",
    "metrics_r2 = tm.R2Score()\n",
    "score_pearsonr = metrics_pearsonr(predicts, labels)\n",
    "score_spearmanr = metrics_spearmanr(predicts, labels)\n",
    "score_mse = metrics_mse(predicts, labels)\n",
    "score_mae = metrics_mae(predicts, labels)\n",
    "score_r2 = metrics_r2(predicts, labels)\n",
    "scores = {\n",
    "    \"pearsonr\": score_pearsonr,\n",
    "    \"spearmanr\": score_spearmanr,\n",
    "    \"mse\": score_mse,\n",
    "    \"mae\": score_mae,\n",
    "    \"r2\": score_r2,\n",
    "    }\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Infer key regulators  \n",
    "\n",
    "Using the fine-tuned model, we analyze embedding similarities between upregulated and unchanged genomic regions. Lower embedding similarity is hypothesized to indicate a greater functional shift, highlighting the potential role of key regulators in cell state transitions.  \n",
    "\n",
    "To save time, we perform the analysis on a downsampled set of upregulated and unchanged genomic regions.  \n",
    "\n",
    "*Note:* Only the selected factors are considered for this analysis, excluding histone modifications and chromatin accessibility.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "update path: mtx_mask = config/hg38_6k_mask_matrix.tsv\n",
      "update path: pretrain_ckpt = checkpoint/hg38_6k_1kb_pretrain.ckpt\n",
      "update path: finetune_ckpt = /home/chenqianqian/.cache/chrombert/data/demo/transdifferentiation/chrom_accessibility/chrom_accessibility_fibroblast_to_myoblast.ckpt\n",
      "use organisim hg38; max sequence length is 6391\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/shared/chenqianqian/data_copy1/chenqianqian/finetune/test_model/ChromBERT_public_2/chrombert/base/model.py:56: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  ck = torch.load(ckpt_path, map_location=torch.device('cpu'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading checkpoint from /home/chenqianqian/.cache/chrombert/data/demo/transdifferentiation/chrom_accessibility/chrom_accessibility_fibroblast_to_myoblast.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/shared/chenqianqian/data_copy1/chenqianqian/finetune/test_model/ChromBERT_public_2/chrombert/finetune/model/basic_model.py:49: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  new_state = torch.load(ckpt)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading from pl module, remove prefix 'model.'\n",
      "Loaded 110/110 parameters\n"
     ]
    }
   ],
   "source": [
    "# Load the fine-tuned model\n",
    "model_tuned = chrombert.get_preset_model_config(\n",
    "    \"general\", \n",
    "    dropout = 0,\n",
    "    finetune_ckpt = f'{chromatin_accessibility_dir}/chrom_accessibility_fibroblast_to_myoblast.ckpt').init_model() # use absolute path here, to avoid mixing of preset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the embedding manager\n",
    "model_emb = model_tuned.get_embedding_manager().cuda()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gather regulator embedding in upregulated genomic regions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "update path: hdf5_file = hg38_6k_1kb.hdf5\n",
      "update path: meta_file = config/hg38_6k_meta.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:05<00:00,  1.34s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([100, 1073, 768])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_config = chrombert.get_preset_dataset_config(\"general\",supervised_file = f'{chromatin_accessibility_dir}/up_data_sample.csv', batch_size = 32, num_workers = 4)\n",
    "up_chrom_acc_embs=[]\n",
    "dl = dataset_config.init_dataloader()\n",
    "for batch in tqdm(dl):\n",
    "    with torch.no_grad():\n",
    "        for k, v in batch.items():\n",
    "            if isinstance(v, torch.Tensor):\n",
    "                batch[k] = v.cuda()\n",
    "        emb = model_emb(batch).cpu()\n",
    "        up_chrom_acc_embs.append(emb)\n",
    "up_chrom_acc_embs = torch.cat(up_chrom_acc_embs,dim=0)\n",
    "up_chrom_acc_embs.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gather regulator embedding in nochange genomic regions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "update path: hdf5_file = hg38_6k_1kb.hdf5\n",
      "update path: meta_file = config/hg38_6k_meta.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:05<00:00,  1.39s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([100, 1073, 768])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_config = chrombert.get_preset_dataset_config(\"general\",supervised_file = f'{chromatin_accessibility_dir}/nochange_data_sample.csv', batch_size = 32, num_workers = 4)\n",
    "nochange_chrom_acc_embs=[]\n",
    "dl = dataset_config.init_dataloader()\n",
    "for batch in tqdm(dl):\n",
    "    with torch.no_grad():\n",
    "        for k, v in batch.items():\n",
    "            if isinstance(v, torch.Tensor):\n",
    "                batch[k] = v.cuda()\n",
    "        emb = model_emb(batch).cpu()\n",
    "        nochange_chrom_acc_embs.append(emb)\n",
    "nochange_chrom_acc_embs = torch.cat(nochange_chrom_acc_embs,dim=0)\n",
    "nochange_chrom_acc_embs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(base_dir, \"config\",\"hg38_6k_factors_list.txt\"),\"r\") as f:\n",
    "    factors = f.read().strip().split(\"\\n\")\n",
    "factors = [f.strip().lower() for f in factors]\n",
    "\n",
    "\n",
    "indices = np.in1d(model_emb.list_regulator,factors)\n",
    "names = np.array(model_emb.list_regulator)[indices]\n",
    "up_chrom_acc_embs = up_chrom_acc_embs.mean(axis=0)[indices]\n",
    "nochange_chrom_acc_embs = nochange_chrom_acc_embs.mean(axis=0)[indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([991, 768]), torch.Size([991, 768]))"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "up_chrom_acc_embs.shape, nochange_chrom_acc_embs.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyze the embedding similarity between upregulated and unchanged genomic regions\n",
    "\n",
    "We calculate the cosine similarity between the embeddings of upregulated and unchanged genomic regions to identify key regulators.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>factors</th>\n",
       "      <th>similarity</th>\n",
       "      <th>rank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>myod1</td>\n",
       "      <td>-0.064511</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>myf5</td>\n",
       "      <td>0.080093</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>myog</td>\n",
       "      <td>0.101807</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>pax3-foxo1a</td>\n",
       "      <td>0.107334</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>tead1</td>\n",
       "      <td>0.214081</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>986</th>\n",
       "      <td>znf250</td>\n",
       "      <td>0.984589</td>\n",
       "      <td>987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>987</th>\n",
       "      <td>hoxa1</td>\n",
       "      <td>0.984709</td>\n",
       "      <td>988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>988</th>\n",
       "      <td>zbtb10</td>\n",
       "      <td>0.985032</td>\n",
       "      <td>989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>989</th>\n",
       "      <td>znf706</td>\n",
       "      <td>0.985040</td>\n",
       "      <td>990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>990</th>\n",
       "      <td>hoxa10</td>\n",
       "      <td>0.986486</td>\n",
       "      <td>991</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>991 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         factors  similarity  rank\n",
       "0          myod1   -0.064511     1\n",
       "1           myf5    0.080093     2\n",
       "2           myog    0.101807     3\n",
       "3    pax3-foxo1a    0.107334     4\n",
       "4          tead1    0.214081     5\n",
       "..           ...         ...   ...\n",
       "986       znf250    0.984589   987\n",
       "987        hoxa1    0.984709   988\n",
       "988       zbtb10    0.985032   989\n",
       "989       znf706    0.985040   990\n",
       "990       hoxa10    0.986486   991\n",
       "\n",
       "[991 rows x 3 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "chrom_acc_similarity = [cosine_similarity(up_chrom_acc_embs[i].reshape(1, -1), nochange_chrom_acc_embs[i].reshape(1, -1))[0, 0] for i in range(up_chrom_acc_embs.shape[0])]\n",
    "chrom_acc_similarity_df = pd.DataFrame({'factors':names,'similarity':chrom_acc_similarity}).sort_values(by='similarity').reset_index(drop=True)\n",
    "chrom_acc_similarity_df['rank']=chrom_acc_similarity_df.index + 1\n",
    "chrom_acc_similarity_df.to_csv(f'{chromatin_accessibility_dir}/chromatin_accessibility_similarity_df.csv',index=False)\n",
    "chrom_acc_similarity_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>factors</th>\n",
       "      <th>similarity</th>\n",
       "      <th>rank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>myod1</td>\n",
       "      <td>-0.064511</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  factors  similarity  rank\n",
       "0   myod1   -0.064511     1"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chrom_acc_similarity_df[chrom_acc_similarity_df['factors']=='myod1']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We identified 25 key regulators in the chromatin accessibility, including the notable regulator 'MYOD1'."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combine the regulator rankings from both chromatin accessibility and transcriptome\n",
    "Final top 25 key regulators derived from average ranks across both chromatin accessibility and transcriptome."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>factors</th>\n",
       "      <th>similarity_gep</th>\n",
       "      <th>rank_gep</th>\n",
       "      <th>similarity_chrom_acc</th>\n",
       "      <th>rank_chrom_acc</th>\n",
       "      <th>averge_rank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>myod1</td>\n",
       "      <td>0.983192</td>\n",
       "      <td>18</td>\n",
       "      <td>-0.064511</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   factors  similarity_gep  rank_gep  similarity_chrom_acc  rank_chrom_acc  \\\n",
       "17   myod1        0.983192        18             -0.064511               1   \n",
       "\n",
       "    averge_rank  \n",
       "17            2  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gep_similarity_path = f'{chromatin_accessibility_dir}/../transcriptome/gep_similarity_df.csv'\n",
    "if not os.path.exists(gep_similarity_path):\n",
    "    raise ValueError(\"Please follow the tutorial for key regulators inference during cell state transition: Transcriptome\")\n",
    "else:\n",
    "    gep_similarity_df = pd.read_csv(gep_similarity_path)\n",
    "    average_rank_df = pd.merge(gep_similarity_df, chrom_acc_similarity_df, on='factors', how='inner', suffixes=('_gep', '_chrom_acc'))\n",
    "    average_rank_df['averge_rank'] = ((average_rank_df['rank_gep']+average_rank_df['rank_chrom_acc'])/2).rank().astype(int)\n",
    "    average_rank_df=average_rank_df.sort_values(by='averge_rank')\n",
    "    average_rank_df\n",
    "    \n",
    "average_rank_df[average_rank_df['factors']=='myod1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['myf5',\n",
       " 'myod1',\n",
       " 'neurog2',\n",
       " 'yap1',\n",
       " 'nr3c2',\n",
       " 'tead1',\n",
       " 'tead',\n",
       " 'dux4',\n",
       " 'pgbd3',\n",
       " 'chd4',\n",
       " 'myog',\n",
       " 'hira',\n",
       " 'pax3-foxo1a',\n",
       " 'tbx5',\n",
       " 'nr3c1',\n",
       " 'snai2',\n",
       " 'ss18',\n",
       " 'prmt5',\n",
       " 'ubn1',\n",
       " 'rb1',\n",
       " 'six2',\n",
       " 'klf11',\n",
       " 'ercc6',\n",
       " 'sumo1',\n",
       " 'esco2']"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_indentified_factor = average_rank_df[average_rank_df['averge_rank']<=25]['factors'].tolist()\n",
    "final_indentified_factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "demo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
