{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example for key regulators inference during cell state transition: Chromatin accessibility\n",
    "To fully inference key regulators during cell state transition, it is essential to combine analyses of chromatin accessibility and the transcriptome. In this tutorial, we will demonstrate how to use ChromBERT to inference key regulators during a specific transdifferentiation process(fibroblast to myoblast) in chromatin accessibility. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]='0'\n",
    "import chrombert\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from torchinfo import summary\n",
    "import subprocess\n",
    "import torch\n",
    "import lightning.pytorch as pl \n",
    "base_dir =  os.path.expanduser(\"~/.cache/chrombert/data\") ### to_path_chrombert/data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess dataset\n",
    "Prepare raw chromatin accessibility data, including peak and BigWig files for the cell type involved in transdifferentiation. This tutorial will guide you on how to format the data for ChromBERT.\n",
    "\n",
    "To identify key regulators, we need to fine-tune ChromBERT to predict log2-transformed chromatin accessibility signal fold changes during transdifferentiation. This process requires the preparation of these transformed data. Additionally, to analyze regulator embedding shifts between upregulated and unchanged loci, we need to prepare and identify data for both loci types. The steps include:\n",
    "\n",
    "-  Considering the total peak regions and gene promoter regions (extending 10 kb from the transcription start site) as background.\n",
    "- Overlapping these regions with 1 kb regions used in ChromBERT.\n",
    "- Extracting chromatin accessibility signals from BigWig files for each of these 1 kb regions.\n",
    "- Calculating log2-transformed chromatin accessibility changes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "chromatin_accessibility_dir = f'{base_dir}/demo/transdifferentiation/chrom_accessibility'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(f'{chromatin_accessibility_dir}/fibroblast_ENCFF184KAM_peak.bed'):\n",
    "     cmd = f'wget https://www.encodeproject.org/files/ENCFF184KAM/@@download/ENCFF184KAM.bed.gz -O {chromatin_accessibility_dir}/fibroblast_ENCFF184KAM_peak.bed'\n",
    "     subprocess.run(cmd, shell=True)\n",
    "if not os.path.exists(f'{chromatin_accessibility_dir}/fibroblast_ENCFF361BTT_signal.bigwig'):\n",
    "     cmd = f'wget https://www.encodeproject.org/files/ENCFF361BTT/@@download/ENCFF361BTT.bigWig -O {chromatin_accessibility_dir}/fibroblast_ENCFF361BTT_signal.bigwig'\n",
    "     subprocess.run(cmd, shell=True)\n",
    "if not os.path.exists(f'{chromatin_accessibility_dir}/myoblast_ENCFF647RNC_peak.bed'):\n",
    "     cmd = f'wget https://www.encodeproject.org/files/ENCFF647RNC/@@download/ENCFF647RNC.bed.gz -O {chromatin_accessibility_dir}/myoblast_ENCFF647RNC_peak.bed'\n",
    "     subprocess.run(cmd, shell=True)\n",
    "if not os.path.exists(f'{chromatin_accessibility_dir}/myoblast_ENCFF149ERN_signal.bigwig'):\n",
    "     cmd = f'wget https://www.encodeproject.org/files/ENCFF149ERN/@@download/ENCFF149ERN.bigWig -O {chromatin_accessibility_dir}/myoblast_ENCFF149ERN_signal.bigwig'\n",
    "     subprocess.run(cmd, shell=True)     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Merge peaks\n",
    "Merge peaks for the cell type involved in transdifferentiation to generate a total peaks file, and then overlap this file with ChromBERT's 1kb bins."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error: Sorted input specified, but the file /home/chenqianqian/.cache/chrombert/data/demo/transdifferentiation/chrom_accessibility/tmp_peak.bed has the following out of order record\n",
      "chr1\t180791\t180871\t.\t0\t.\t0.0397844\t-1\t-1\t75\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CompletedProcess(args='bedtools merge -i /home/chenqianqian/.cache/chrombert/data/demo/transdifferentiation/chrom_accessibility/tmp_peak.bed > /home/chenqianqian/.cache/chrombert/data/demo/transdifferentiation/chrom_accessibility/total_peak.bed', returncode=1)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cmd = f\"cat {chromatin_accessibility_dir}/fibroblast_ENCFF184KAM_peak.bed {chromatin_accessibility_dir}/myoblast_ENCFF647RNC_peak.bed > {chromatin_accessibility_dir}/tmp_peak.bed\"\n",
    "subprocess.run(cmd, shell=True)\n",
    "cmd = f\"bedtools merge -i {chromatin_accessibility_dir}/tmp_peak.bed > {chromatin_accessibility_dir}/total_peak.bed\"\n",
    "subprocess.run(cmd, shell=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(249604,\n",
       "   chrom   start     end  build_region_index\n",
       " 0  chr1  181000  182000                  39\n",
       " 1  chr1  191000  192000                  46\n",
       " 2  chr1  268000  269000                  54\n",
       " 3  chr1  729000  730000                  93\n",
       " 4  chr1  778000  779000                 102)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from chrombert.scripts.chrombert_make_dataset import get_regions,process\n",
    "chrom_regions = get_regions(base_dir,genome='hg38',high_resolution=False) # 1kb\n",
    "total_peak_process = process(f'{chromatin_accessibility_dir}/total_peak.bed',chrom_regions,mode='region')[['chrom','start','end','build_region_index']]\n",
    "len(total_peak_process),total_peak_process.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generate background regions\n",
    "Include promoter TSS regions (within 10kb) as background samples and overlap these areas with ChromBERT's 1kb bins."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>chrom</th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>chr19</td>\n",
       "      <td>58343492</td>\n",
       "      <td>58363492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>chr19</td>\n",
       "      <td>58337718</td>\n",
       "      <td>58357718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>chr10</td>\n",
       "      <td>50875675</td>\n",
       "      <td>50895675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>chr12</td>\n",
       "      <td>9106229</td>\n",
       "      <td>9126229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>chr12</td>\n",
       "      <td>9055163</td>\n",
       "      <td>9075163</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   chrom     start       end\n",
       "0  chr19  58343492  58363492\n",
       "1  chr19  58337718  58357718\n",
       "2  chr10  50875675  50895675\n",
       "3  chr12   9106229   9126229\n",
       "4  chr12   9055163   9075163"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gep_df = pd.read_csv(f'{chromatin_accessibility_dir}/../transcriptome/fibroblast_to_myoblast_expression_changes.csv')\n",
    "gep_df_tss_10kb = pd.DataFrame({'chrom':gep_df['chrom'],'start':gep_df['tss']-10000,'end':gep_df['tss']+10000})\n",
    "gep_df_tss_10kb\n",
    "gep_df_tss_10kb.to_csv(f'{chromatin_accessibility_dir}/gep_df_tss_10kb.bed',sep='\\t',index=False,header=None)\n",
    "gep_df_tss_10kb.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(295682,\n",
       "   chrom   start     end  build_region_index\n",
       " 0  chr1  815000  816000                 126\n",
       " 1  chr1  816000  817000                 127\n",
       " 2  chr1  817000  818000                 128\n",
       " 3  chr1  818000  819000                 129\n",
       " 4  chr1  819000  820000                 130)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gep_df_tss_10kb_process = process(f'{chromatin_accessibility_dir}/gep_df_tss_10kb.bed',chrom_regions,mode='region').drop_duplicates(subset='build_region_index')[['chrom','start','end','build_region_index']]\n",
    "len(gep_df_tss_10kb_process),gep_df_tss_10kb_process.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Merge total peaks and background regions\n",
    "Generate the total region by concatenating the total peak and background regions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(491615,\n",
       "   chrom   start     end  build_region_index\n",
       " 0  chr1  181000  182000                  39\n",
       " 1  chr1  191000  192000                  46\n",
       " 2  chr1  268000  269000                  54\n",
       " 3  chr1  729000  730000                  93\n",
       " 4  chr1  778000  779000                 102)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_region_processed = pd.concat([total_peak_process,gep_df_tss_10kb_process],axis=0).drop_duplicates().reset_index(drop=True)\n",
    "total_region_processed.to_csv(f'{chromatin_accessibility_dir}/total_region_processed.csv',index=False)\n",
    "len(total_region_processed),total_region_processed.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extract the chromatin accessibility signals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import bbi  # pip install pybbi\n",
    "def bw_getSignal_bins(\n",
    "    bw, regions:pd.DataFrame,name\n",
    "    ):\n",
    "    regions = regions.copy()\n",
    "    with bbi.open(str(bw)) as bwf:\n",
    "        mtx = bwf.stackup(regions[\"chrom\"],regions[\"start\"],regions[\"end\"], bins=1, missing=0)\n",
    "        mean= bwf.info[\"summary\"][\"mean\"]\n",
    "        mtx = mtx/mean\n",
    "    df_signal = pd.DataFrame(data = mtx, columns = [f'{name}_signal'])\n",
    "    return df_signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "fibroblast_signal = bw_getSignal_bins(bw=f'{chromatin_accessibility_dir}/fibroblast_ENCFF361BTT_signal.bigwig',regions=total_region_processed,name='fibroblast')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "myoblast_signal = bw_getSignal_bins(bw=f'{chromatin_accessibility_dir}/myoblast_ENCFF149ERN_signal.bigwig',regions=total_region_processed,name='myoblast')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prepare the log2-transformed chromatin accessibility signal fold changes data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>chrom</th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "      <th>build_region_index</th>\n",
       "      <th>label</th>\n",
       "      <th>fibroblast_signal</th>\n",
       "      <th>myoblast_signal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>chr1</td>\n",
       "      <td>181000</td>\n",
       "      <td>182000</td>\n",
       "      <td>39</td>\n",
       "      <td>0.001996</td>\n",
       "      <td>2.543848</td>\n",
       "      <td>2.548754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>chr1</td>\n",
       "      <td>191000</td>\n",
       "      <td>192000</td>\n",
       "      <td>46</td>\n",
       "      <td>-0.678009</td>\n",
       "      <td>1.386900</td>\n",
       "      <td>0.491877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>chr1</td>\n",
       "      <td>268000</td>\n",
       "      <td>269000</td>\n",
       "      <td>54</td>\n",
       "      <td>-0.329329</td>\n",
       "      <td>1.324022</td>\n",
       "      <td>0.849704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>chr1</td>\n",
       "      <td>729000</td>\n",
       "      <td>730000</td>\n",
       "      <td>93</td>\n",
       "      <td>-0.491940</td>\n",
       "      <td>0.470683</td>\n",
       "      <td>0.045756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>chr1</td>\n",
       "      <td>778000</td>\n",
       "      <td>779000</td>\n",
       "      <td>102</td>\n",
       "      <td>0.098767</td>\n",
       "      <td>37.696015</td>\n",
       "      <td>40.437941</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  chrom   start     end  build_region_index     label  fibroblast_signal  \\\n",
       "0  chr1  181000  182000                  39  0.001996           2.543848   \n",
       "1  chr1  191000  192000                  46 -0.678009           1.386900   \n",
       "2  chr1  268000  269000                  54 -0.329329           1.324022   \n",
       "3  chr1  729000  730000                  93 -0.491940           0.470683   \n",
       "4  chr1  778000  779000                 102  0.098767          37.696015   \n",
       "\n",
       "   myoblast_signal  \n",
       "0         2.548754  \n",
       "1         0.491877  \n",
       "2         0.849704  \n",
       "3         0.045756  \n",
       "4        40.437941  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_region_signal_processed = pd.concat([total_region_processed,fibroblast_signal,myoblast_signal],axis=1)\n",
    "total_region_signal_processed['fold_change'] = np.log2(1+total_region_signal_processed['myoblast_signal']) - np.log2(1+total_region_signal_processed['fibroblast_signal'])\n",
    "total_region_signal_processed\n",
    "chrom_accessibility_df = total_region_signal_processed[['chrom','start','end','build_region_index','fold_change','fibroblast_signal','myoblast_signal']].rename(columns={'fold_change':'label'})\n",
    "chrom_accessibility_df.to_csv(f'{chromatin_accessibility_dir}/fibroblast_to_myoblast_chrom_accessibility_changes.csv',index=False)\n",
    "chrom_accessibility_df.head() ### This label represents log2-transformed chromatin accessibility signal fold changes.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prepare fine-tuning data\n",
    "Splitting it into training, testing, and validation sets with an 8:1:1 ratio and Downsample the data to test the fine-tuning process\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>chrom</th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "      <th>build_region_index</th>\n",
       "      <th>label</th>\n",
       "      <th>fibroblast_signal</th>\n",
       "      <th>myoblast_signal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>267005</th>\n",
       "      <td>chr1</td>\n",
       "      <td>160963000</td>\n",
       "      <td>160964000</td>\n",
       "      <td>111173</td>\n",
       "      <td>0.253080</td>\n",
       "      <td>0.235342</td>\n",
       "      <td>0.472217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>458923</th>\n",
       "      <td>chr7</td>\n",
       "      <td>73835000</td>\n",
       "      <td>73836000</td>\n",
       "      <td>1798466</td>\n",
       "      <td>0.044447</td>\n",
       "      <td>0.034134</td>\n",
       "      <td>0.066489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50428</th>\n",
       "      <td>chr12</td>\n",
       "      <td>41932000</td>\n",
       "      <td>41933000</td>\n",
       "      <td>415524</td>\n",
       "      <td>-0.245291</td>\n",
       "      <td>1.433608</td>\n",
       "      <td>1.053103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>250859</th>\n",
       "      <td>chr1</td>\n",
       "      <td>8210000</td>\n",
       "      <td>8211000</td>\n",
       "      <td>6478</td>\n",
       "      <td>0.191804</td>\n",
       "      <td>0.302711</td>\n",
       "      <td>0.487945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>370974</th>\n",
       "      <td>chr19</td>\n",
       "      <td>50858000</td>\n",
       "      <td>50859000</td>\n",
       "      <td>912107</td>\n",
       "      <td>0.274903</td>\n",
       "      <td>0.195819</td>\n",
       "      <td>0.446836</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        chrom      start        end  build_region_index     label  \\\n",
       "267005   chr1  160963000  160964000              111173  0.253080   \n",
       "458923   chr7   73835000   73836000             1798466  0.044447   \n",
       "50428   chr12   41932000   41933000              415524 -0.245291   \n",
       "250859   chr1    8210000    8211000                6478  0.191804   \n",
       "370974  chr19   50858000   50859000              912107  0.274903   \n",
       "\n",
       "        fibroblast_signal  myoblast_signal  \n",
       "267005           0.235342         0.472217  \n",
       "458923           0.034134         0.066489  \n",
       "50428            1.433608         1.053103  \n",
       "250859           0.302711         0.487945  \n",
       "370974           0.195819         0.446836  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data = chrom_accessibility_df.sample(frac=0.8,random_state=55)\n",
    "test_data = chrom_accessibility_df.drop(train_data.index).sample(frac=0.5,random_state=55)\n",
    "valid_data = chrom_accessibility_df.drop(train_data.index).drop(test_data.index)\n",
    "\n",
    "train_data_sample = train_data.sample(n=80,random_state=55)\n",
    "test_data_sample = test_data.sample(n=20,random_state=55)\n",
    "valid_data_sample = valid_data.sample(n=20,random_state=55)\n",
    "\n",
    "\n",
    "train_data_sample.to_csv(f'{chromatin_accessibility_dir}/train_sample.csv',index=False)\n",
    "test_data_sample.to_csv(f'{chromatin_accessibility_dir}/test_sample.csv',index=False)\n",
    "valid_data_sample.to_csv(f'{chromatin_accessibility_dir}/valid_sample.csv',index=False)\n",
    "train_data_sample.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prepare the upregulated loci and unchanged loci \n",
    "\n",
    "Loci showing a log2-transformed chrom accessibility difference greater than 2 were marked as having increased chromatin accessibility, Uncovered regions were excluded, with the top 40,000 loci showing the absolute fold changes selected as those with unchanged accessibility."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_31920/1160250605.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  covered_region['label_abs'] = np.abs(covered_region['label'])\n"
     ]
    }
   ],
   "source": [
    "chrom_accessibility_df = pd.read_csv(f'{chromatin_accessibility_dir}/fibroblast_to_myoblast_chrom_accessibility_changes.csv')\n",
    "up_data = chrom_accessibility_df[chrom_accessibility_df['label']>2]\n",
    "\n",
    "covered_region = chrom_accessibility_df[(chrom_accessibility_df['fibroblast_signal']>0) & (chrom_accessibility_df['myoblast_signal']>0)]\n",
    "covered_region['label_abs'] = np.abs(covered_region['label'])\n",
    "nochange_data = covered_region.sort_values('label_abs').reset_index(drop=True).iloc[0:40000]\n",
    "\n",
    "\n",
    "up_data_sample = up_data.sample(n=100,random_state=55)\n",
    "nochange_data_sample = nochange_data.sample(n=100,random_state=55)\n",
    "\n",
    "\n",
    "up_data_sample.to_csv(f'{chromatin_accessibility_dir}/up_data_sample.csv',index=False)\n",
    "nochange_data_sample.to_csv(f'{chromatin_accessibility_dir}/nochange_data_sample.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fine-tune\n",
    "\n",
    "In this section, we provide a tutorial for fine-tuning ChromBERTs to predict genome-wide changes in chromatin accessibility. \n",
    "The fine-tuning process for chromatin accessibility is general. \n",
    "- Dataset config Preparation: We use the `general` preset dataset config\n",
    "- Model Instantiation: We use the `general` preset model config\n",
    "Let's get started!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set data config and data module\n",
    "We use the `general` preset dataset config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "update path: hdf5_file = hg38_6k_1kb.hdf5\n",
      "update path: meta_file = config/hg38_6k_meta.json\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DatasetConfig({'hdf5_file': '/home/chenqianqian/.cache/chrombert/data/hg38_6k_1kb.hdf5', 'supervised_file': None, 'kind': 'GeneralDataset', 'meta_file': '/home/chenqianqian/.cache/chrombert/data/config/hg38_6k_meta.json', 'ignore': False, 'ignore_object': None, 'batch_size': 4, 'num_workers': 4, 'shuffle': False, 'perturbation': False, 'perturbation_object': None, 'perturbation_value': 0, 'prompt_kind': None, 'prompt_regulator': None, 'prompt_regulator_cache_file': None, 'prompt_celltype': None, 'prompt_celltype_cache_file': None, 'fasta_file': None, 'flank_window': 0})"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_config = chrombert.get_preset_dataset_config(\"general\",supervised_file = None, batch_size = 4, num_workers = 4)\n",
    "dataset_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_module = chrombert.LitChromBERTFTDataModule(\n",
    "    config = dataset_config, \n",
    "    train_params = {'supervised_file': f'{chromatin_accessibility_dir}/train_sample.csv'}, \n",
    "    val_params = {'supervised_file':f'{chromatin_accessibility_dir}/valid_sample.csv'}, \n",
    "    test_params = {'supervised_file':f'{chromatin_accessibility_dir}/test_sample.csv'}\n",
    ")\n",
    "data_module.setup()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set model config and load model\n",
    "\n",
    "we use `general` preset model config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "update path: mtx_mask = config/hg38_6k_mask_matrix.tsv\n",
      "update path: pretrain_ckpt = checkpoint/hg38_6k_1kb_pretrain.ckpt\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ChromBERTFTConfig:\n",
       "{\n",
       "    \"genome\": \"hg38\",\n",
       "    \"task\": \"general\",\n",
       "    \"dim_output\": 1,\n",
       "    \"mtx_mask\": \"/home/chenqianqian/.cache/chrombert/data/config/hg38_6k_mask_matrix.tsv\",\n",
       "    \"dropout\": 0.1,\n",
       "    \"pretrain_ckpt\": \"/home/chenqianqian/.cache/chrombert/data/checkpoint/hg38_6k_1kb_pretrain.ckpt\",\n",
       "    \"finetune_ckpt\": null,\n",
       "    \"ignore\": false,\n",
       "    \"ignore_index\": [\n",
       "        null,\n",
       "        null\n",
       "    ],\n",
       "    \"gep_flank_window\": 4,\n",
       "    \"gep_parallel_embedding\": false,\n",
       "    \"gep_gradient_checkpoint\": false,\n",
       "    \"gep_zero_inflation\": true,\n",
       "    \"prompt_kind\": \"cistrome\",\n",
       "    \"prompt_dim_external\": 512,\n",
       "    \"dnabert2_ckpt\": null\n",
       "}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_config = chrombert.get_preset_model_config(\"general\")\n",
    "model_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "use organisim hg38; max sequence length including cls is 6392\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "================================================================================\n",
       "Layer (type:depth-idx)                                  Param #\n",
       "================================================================================\n",
       "ChromBERTGeneral                                        --\n",
       "├─ChromBERT: 1-1                                        --\n",
       "│    └─BERTEmbedding: 2-1                               --\n",
       "│    │    └─TokenEmbedding: 3-1                         (7,680)\n",
       "│    │    └─PositionalEmbedding: 3-2                    (4,909,056)\n",
       "│    │    └─Dropout: 3-3                                --\n",
       "│    └─ModuleList: 2-2                                  --\n",
       "│    │    └─EncoderTransformerBlock: 3-4                (6,497,280)\n",
       "│    │    └─EncoderTransformerBlock: 3-5                (6,497,280)\n",
       "│    │    └─EncoderTransformerBlock: 3-6                (6,497,280)\n",
       "│    │    └─EncoderTransformerBlock: 3-7                (6,497,280)\n",
       "│    │    └─EncoderTransformerBlock: 3-8                (6,497,280)\n",
       "│    │    └─EncoderTransformerBlock: 3-9                (6,497,280)\n",
       "│    │    └─EncoderTransformerBlock: 3-10               6,497,280\n",
       "│    │    └─EncoderTransformerBlock: 3-11               6,497,280\n",
       "├─GeneralHeader: 1-2                                    --\n",
       "│    └─CistromeEmbeddingManager: 2-3                    --\n",
       "│    └─Conv2d: 2-4                                      769\n",
       "│    └─ReLU: 2-5                                        --\n",
       "│    └─ResidualBlock: 2-6                               --\n",
       "│    │    └─Linear: 3-12                                1,090,560\n",
       "│    │    └─Linear: 3-13                                1,049,600\n",
       "│    │    └─LayerNorm: 3-14                             2,048\n",
       "│    │    └─Linear: 3-15                                1,090,560\n",
       "│    │    └─Dropout: 3-16                               --\n",
       "│    └─ResidualBlock: 2-7                               --\n",
       "│    │    └─Linear: 3-17                                787,200\n",
       "│    │    └─Linear: 3-18                                590,592\n",
       "│    │    └─LayerNorm: 3-19                             1,536\n",
       "│    │    └─Linear: 3-20                                787,200\n",
       "│    │    └─Dropout: 3-21                               --\n",
       "│    └─ResidualBlock: 2-8                               --\n",
       "│    │    └─Linear: 3-22                                196,864\n",
       "│    │    └─Linear: 3-23                                65,792\n",
       "│    │    └─LayerNorm: 3-24                             512\n",
       "│    │    └─Linear: 3-25                                196,864\n",
       "│    │    └─Dropout: 3-26                               --\n",
       "│    └─Linear: 2-9                                      257\n",
       "================================================================================\n",
       "Total params: 62,755,330\n",
       "Trainable params: 18,854,914\n",
       "Non-trainable params: 43,900,416\n",
       "================================================================================"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = model_config.init_model()\n",
    "model.freeze_pretrain(2) ### freeze chrombert 6 transformer blocks\n",
    "summary(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set train config and fine-tune\n",
    "\n",
    "We fine-tune the model using PyTorch Lightning. A simple configuration is created to process parameters, and fine-tuning is performed on a limited dataset to save time.\n",
    "Note: The tuning process is random, so results may vary. To achieve the best results, consider increasing the number of epochs and the size of the dataset used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/chenqianqian/.conda/envs/demo/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: Metric `SpearmanCorrcoef` will save all targets and predictions in the buffer. For large datasets, this may lead to large memory footprint.\n",
      "  warnings.warn(*args, **kwargs)  # noqa: B028\n"
     ]
    }
   ],
   "source": [
    "train_config = chrombert.finetune.TrainConfig(kind='regression',        \n",
    "                                              loss='rmse',\n",
    "                                              max_epochs=2,\n",
    "                                              accumulate_grad_batches=2,\n",
    "                                              val_check_interval=2,\n",
    "                                              limit_val_batches=10,\n",
    "                                              tag='chrom_accessibility')\n",
    "train_config\n",
    "train_module = train_config.init_pl_module(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using bfloat16 Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "You are using a CUDA device ('NVIDIA A100-PCIE-40GB') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "Missing logger folder: lightning_logs/chrom_accessibility\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "\n",
      "  | Name  | Type             | Params | Mode \n",
      "---------------------------------------------------\n",
      "0 | model | ChromBERTGeneral | 62.8 M | train\n",
      "---------------------------------------------------\n",
      "18.9 M    Trainable params\n",
      "43.9 M    Non-trainable params\n",
      "62.8 M    Total params\n",
      "251.021   Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1ba7ef1632f24fb1be92082fb0c9709f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/chenqianqian/.conda/envs/demo/lib/python3.9/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:475: Your `val_dataloader`'s sampler has shuffling enabled, it is strongly recommended that you turn shuffling off for val/test dataloaders.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f0e04a26c9847108e08a5e1c8740f2c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "031a27f380e44a99b33b141f34c6c546",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9f14fc5107c04f3283a867a0beae926a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e7a88fd469864535bf61477ddaf218a5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f4d6197e096b4cd78d0003f5e4bddf28",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "766684a98d7d42f8bbdaac07a5ba37ed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae1a47650601457cb4ee452b7dfa1cb3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "44cccc988eee4e89af6051af80ae9617",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "21d066c8c29b41609407eb4008faf027",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/chenqianqian/.conda/envs/demo/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: The variance of predictions or target is close to zero. This can cause instability in Pearson correlationcoefficient, leading to wrong results. Consider re-scaling the input if possible or computing using alarger dtype (currently using torch.float32).\n",
      "  warnings.warn(*args, **kwargs)  # noqa: B028\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c87b71eb93984cc68118acac65727a22",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5fe61e6520fa466cac8abeb3fd7a177e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f9e08ec5e21b447db2618405c1e33ba4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "03a695b5a8f04c7d97de55cb5e4f6696",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "54498071f9c0440abccf51f8d4eba977",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bb07d853252b4e2b93cf12e75749adb8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "69ad51b4049247d4898560ab642ff7a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b5ef56d4c96f4ffc9e7156faea3bfb28",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "446e52364fd0427eabc7b0b263ab8512",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1b723f3b27664660b5483a44626c8764",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f04ac52419ee4046b8e8d6fabe14153a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7b219ccff61a4675841113ae2ec290d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=2` reached.\n"
     ]
    }
   ],
   "source": [
    "callback_ckpt = pl.callbacks.ModelCheckpoint(monitor = f\"{train_config.tag}_validation/{train_config.loss}\", mode = \"min\")\n",
    "trainer = pl.Trainer(\n",
    "    max_epochs=train_config.max_epochs,\n",
    "    log_every_n_steps=1, \n",
    "    limit_val_batches = train_config.limit_val_batches,\n",
    "    val_check_interval = train_config.val_check_interval,\n",
    "    accelerator=\"gpu\", \n",
    "    accumulate_grad_batches= train_config.accumulate_grad_batches, \n",
    "    fast_dev_run=False, \n",
    "    precision=\"bf16-mixed\",\n",
    "    strategy=\"auto\",\n",
    "    callbacks=[\n",
    "        pl.callbacks.LearningRateMonitor(),\n",
    "        callback_ckpt,   \n",
    "    ],\n",
    "    logger=pl.loggers.TensorBoardLogger(\"lightning_logs\", name='chrom_accessibility'),\n",
    "    )\n",
    "trainer.fit(train_module,data_module)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate fine-tuned model\n",
    "ChromBERT has been successfully fine-tuned! Evaluate the model directly using `pl_module.model`. Please note, due to flash-attention settings, dropout probability cannot be altered, potentially adding randomness to the output. \n",
    "\n",
    "For consistent results, save the checkpoint and reload it into the original model configuration to ensure accuracy of the fine-tuned model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluate fine-tuned model with limited data\n",
    "Due to tutorial time constraints, we use only downsampled test data for evaluation.\n",
    "\n",
    "Note: This model is fine-tuned using limited data. If performance is suboptimal, consider fine-tuning with the complete dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "update path: mtx_mask = config/hg38_6k_mask_matrix.tsv\n",
      "update path: pretrain_ckpt = checkpoint/hg38_6k_1kb_pretrain.ckpt\n",
      "use organisim hg38; max sequence length including cls is 6392\n",
      "Loading checkpoint from /shared/chenqianqian/data_copy1/chenqianqian/finetune/test_model/ChromBERT_public/examples/tutorials/lightning_logs/chrom_accessibility/version_0/checkpoints/epoch=0-step=1.ckpt\n",
      "Loading from pl module, remove prefix 'model.'\n",
      "Loaded 110/110 parameters\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "chrom_accessibility_ft_ckpt = os.path.abspath(glob.glob('./lightning_logs/chrom_accessibility/version_*/checkpoints/*.ckpt')[0])\n",
    "chrom_accessibility_ft_ckpt\n",
    "model_config = chrombert.get_preset_model_config(\"general\")\n",
    "ft_model = model_config.init_model(finetune_ckpt = chrom_accessibility_ft_ckpt,dropout=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:01<00:00,  2.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'pearsonr': tensor(-0.1530), 'spearmanr': tensor(0.1203), 'mse': tensor(0.5459), 'mae': tensor(0.4250), 'r2': tensor(-0.3871)}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "/home/chenqianqian/.conda/envs/demo/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: Metric `SpearmanCorrcoef` will save all targets and predictions in the buffer. For large datasets, this may lead to large memory footprint.\n",
      "  warnings.warn(*args, **kwargs)  # noqa: B028\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "import torchmetrics as tm\n",
    "dl = data_module.test_dataloader()\n",
    "ft_model = ft_model.cuda().eval()\n",
    "with torch.no_grad():\n",
    "    y_preds = []\n",
    "    y_labels = []\n",
    "    for batch in tqdm(dl,total=len(dl)):\n",
    "        for k in batch:\n",
    "            if isinstance(batch[k], torch.Tensor):\n",
    "                batch[k] = batch[k].cuda()\n",
    "        y_pred = ft_model(batch).cpu()\n",
    "        y_label = batch['label'].cpu()\n",
    "        y_preds.append(y_pred)\n",
    "        y_labels.append(y_label)\n",
    "    y_preds = torch.cat(y_preds)\n",
    "    y_labels = torch.cat(y_labels)\n",
    "predicts = y_preds.view(-1)\n",
    "labels = y_labels.view(-1)\n",
    "metrics_pearsonr = tm.PearsonCorrCoef()\n",
    "metrics_spearmanr = tm.SpearmanCorrCoef()\n",
    "metrics_mse = tm.MeanSquaredError()\n",
    "metrics_mae = tm.MeanAbsoluteError()\n",
    "metrics_r2 = tm.R2Score()\n",
    "score_pearsonr = metrics_pearsonr(predicts, labels)\n",
    "score_spearmanr = metrics_spearmanr(predicts, labels)\n",
    "score_mse = metrics_mse(predicts, labels)\n",
    "score_mae = metrics_mae(predicts, labels)\n",
    "score_r2 = metrics_r2(predicts, labels)\n",
    "scores = {\n",
    "    \"pearsonr\": score_pearsonr,\n",
    "    \"spearmanr\": score_spearmanr,\n",
    "    \"mse\": score_mse,\n",
    "    \"mae\": score_mae,\n",
    "    \"r2\": score_r2,\n",
    "    }\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluate fine-tuned model with entire dataset\n",
    "The model initially fine-tuned with limited data showed poor performance upon evaluation. \n",
    "We have fine-tuned model using the entire dataset to enhance its performance for predicting genome-wide changes in the chromatin accessibility and have provided a checkpoint. Due to time constraints in tutorial, we only use downsampled test data for evaluation this model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "update path: mtx_mask = config/hg38_6k_mask_matrix.tsv\n",
      "update path: pretrain_ckpt = checkpoint/hg38_6k_1kb_pretrain.ckpt\n",
      "use organisim hg38; max sequence length including cls is 6392\n",
      "Loading checkpoint from /home/chenqianqian/.cache/chrombert/data/demo/transdifferentiation/chrom_accessibility/chrom_accessibility_fibroblast_to_myoblast.ckpt\n",
      "Loaded 110/110 parameters\n"
     ]
    }
   ],
   "source": [
    "chrom_accessibility_ft_ckpt = f'{chromatin_accessibility_dir}/chrom_accessibility_fibroblast_to_myoblast.ckpt'\n",
    "model_config = chrombert.get_preset_model_config(\"general\")\n",
    "ft_model = model_config.init_model(finetune_ckpt = chrom_accessibility_ft_ckpt,dropout=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:02<00:00,  1.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'pearsonr': tensor(0.8971), 'spearmanr': tensor(0.8857), 'mse': tensor(0.0807), 'mae': tensor(0.1940), 'r2': tensor(0.7950)}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "/home/chenqianqian/.conda/envs/demo/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: Metric `SpearmanCorrcoef` will save all targets and predictions in the buffer. For large datasets, this may lead to large memory footprint.\n",
      "  warnings.warn(*args, **kwargs)  # noqa: B028\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "import torchmetrics as tm\n",
    "dl = data_module.test_dataloader()\n",
    "ft_model = ft_model.cuda().eval()\n",
    "with torch.no_grad():\n",
    "    y_preds = []\n",
    "    y_labels = []\n",
    "    for batch in tqdm(dl,total=len(dl)):\n",
    "        for k in batch:\n",
    "            if isinstance(batch[k], torch.Tensor):\n",
    "                batch[k] = batch[k].cuda()\n",
    "        y_pred = ft_model(batch).cpu()\n",
    "        y_label = batch['label'].cpu()\n",
    "        y_preds.append(y_pred)\n",
    "        y_labels.append(y_label)\n",
    "    y_preds = torch.cat(y_preds)\n",
    "    y_labels = torch.cat(y_labels)\n",
    "predicts = y_preds.view(-1)\n",
    "labels = y_labels.view(-1)\n",
    "metrics_pearsonr = tm.PearsonCorrCoef()\n",
    "metrics_spearmanr = tm.SpearmanCorrCoef()\n",
    "metrics_mse = tm.MeanSquaredError()\n",
    "metrics_mae = tm.MeanAbsoluteError()\n",
    "metrics_r2 = tm.R2Score()\n",
    "score_pearsonr = metrics_pearsonr(predicts, labels)\n",
    "score_spearmanr = metrics_spearmanr(predicts, labels)\n",
    "score_mse = metrics_mse(predicts, labels)\n",
    "score_mae = metrics_mae(predicts, labels)\n",
    "score_r2 = metrics_r2(predicts, labels)\n",
    "scores = {\n",
    "    \"pearsonr\": score_pearsonr,\n",
    "    \"spearmanr\": score_spearmanr,\n",
    "    \"mse\": score_mse,\n",
    "    \"mae\": score_mae,\n",
    "    \"r2\": score_r2,\n",
    "    }\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference key regulator\n",
    "\n",
    "We analyze the embedding similarity between upregulated and unchanged loci using the fine-tuned model. We hypothesize that lower embedding similarity indicates a larger shift, suggesting a regulator's significant role in cell state transitions. This approach helps identify key regulators.\n",
    "\n",
    "Due to time constraints in this tutorial, we will use only a downsampled set of upregulated and unchanged loci for our analysis.\n",
    "\n",
    "Notion: We consider only factors below, remove histone modifications and chromatin accessibility. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "update path: mtx_mask = config/hg38_6k_mask_matrix.tsv\n",
      "update path: pretrain_ckpt = checkpoint/hg38_6k_1kb_pretrain.ckpt\n",
      "update path: finetune_ckpt = /home/chenqianqian/.cache/chrombert/data/demo/transdifferentiation/chrom_accessibility/chrom_accessibility_fibroblast_to_myoblast.ckpt\n",
      "use organisim hg38; max sequence length including cls is 6392\n",
      "Loading checkpoint from /home/chenqianqian/.cache/chrombert/data/demo/transdifferentiation/chrom_accessibility/chrom_accessibility_fibroblast_to_myoblast.ckpt\n",
      "Loaded 110/110 parameters\n"
     ]
    }
   ],
   "source": [
    "model_tuned = chrombert.get_preset_model_config(\n",
    "    \"general\", \n",
    "    dropout = 0,\n",
    "    finetune_ckpt = f'{chromatin_accessibility_dir}/chrom_accessibility_fibroblast_to_myoblast.ckpt').init_model() # use absolute path here, to avoid mixing of preset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_emb = model_tuned.get_embedding_manager().cuda()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pick regulator embedding in upregulated loci"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "update path: hdf5_file = hg38_6k_1kb.hdf5\n",
      "update path: meta_file = config/hg38_6k_meta.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:11<00:00,  2.82s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([100, 1064, 768])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_config = chrombert.get_preset_dataset_config(\"general\",supervised_file = f'{chromatin_accessibility_dir}/up_data_sample.csv', batch_size = 32, num_workers = 4)\n",
    "up_chrom_acc_embs=[]\n",
    "dl = dataset_config.init_dataloader()\n",
    "for batch in tqdm(dl):\n",
    "    with torch.no_grad():\n",
    "        for k, v in batch.items():\n",
    "            if isinstance(v, torch.Tensor):\n",
    "                batch[k] = v.cuda()\n",
    "        emb = model_emb(batch).cpu()\n",
    "        up_chrom_acc_embs.append(emb)\n",
    "up_chrom_acc_embs = torch.cat(up_chrom_acc_embs,dim=0)\n",
    "up_chrom_acc_embs.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pick regulator embedding in nochange loci"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "update path: hdf5_file = hg38_6k_1kb.hdf5\n",
      "update path: meta_file = config/hg38_6k_meta.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:11<00:00,  2.82s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([100, 1064, 768])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_config = chrombert.get_preset_dataset_config(\"general\",supervised_file = f'{chromatin_accessibility_dir}/nochange_data_sample.csv', batch_size = 32, num_workers = 4)\n",
    "nochange_chrom_acc_embs=[]\n",
    "dl = dataset_config.init_dataloader()\n",
    "for batch in tqdm(dl):\n",
    "    with torch.no_grad():\n",
    "        for k, v in batch.items():\n",
    "            if isinstance(v, torch.Tensor):\n",
    "                batch[k] = v.cuda()\n",
    "        emb = model_emb(batch).cpu()\n",
    "        nochange_chrom_acc_embs.append(emb)\n",
    "nochange_chrom_acc_embs = torch.cat(nochange_chrom_acc_embs,dim=0)\n",
    "nochange_chrom_acc_embs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(base_dir, \"config\",\"hg38_6k_factors_list.txt\"),\"r\") as f:\n",
    "    factors = f.read().strip().split(\"\\n\")\n",
    "factors = [f.strip().lower() for f in factors]\n",
    "\n",
    "\n",
    "indices = np.in1d(model_emb.list_regulator,factors)\n",
    "names = np.array(model_emb.list_regulator)[indices]\n",
    "up_chrom_acc_embs = up_chrom_acc_embs.mean(axis=0)[indices]\n",
    "nochange_chrom_acc_embs = nochange_chrom_acc_embs.mean(axis=0)[indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([992, 768]), torch.Size([992, 768]))"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "up_chrom_acc_embs.shape, nochange_chrom_acc_embs.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyze the embedding similarity between upregulated and unchanged loci\n",
    "We hypothesize that lower embedding similarity indicates a larger shift, suggesting a regulator's significant role in cell state transitions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>factors</th>\n",
       "      <th>similarity</th>\n",
       "      <th>rank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>myod1</td>\n",
       "      <td>0.038196</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>myf5</td>\n",
       "      <td>0.139169</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>myog</td>\n",
       "      <td>0.158149</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>pax3</td>\n",
       "      <td>0.169502</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>tead1</td>\n",
       "      <td>0.264310</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>987</th>\n",
       "      <td>zbtb10</td>\n",
       "      <td>0.979514</td>\n",
       "      <td>988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>988</th>\n",
       "      <td>znf250</td>\n",
       "      <td>0.979778</td>\n",
       "      <td>989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>989</th>\n",
       "      <td>dr1</td>\n",
       "      <td>0.980107</td>\n",
       "      <td>990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>990</th>\n",
       "      <td>hoxa1</td>\n",
       "      <td>0.980110</td>\n",
       "      <td>991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>991</th>\n",
       "      <td>barhl1</td>\n",
       "      <td>0.981534</td>\n",
       "      <td>992</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>992 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    factors  similarity  rank\n",
       "0     myod1    0.038196     1\n",
       "1      myf5    0.139169     2\n",
       "2      myog    0.158149     3\n",
       "3      pax3    0.169502     4\n",
       "4     tead1    0.264310     5\n",
       "..      ...         ...   ...\n",
       "987  zbtb10    0.979514   988\n",
       "988  znf250    0.979778   989\n",
       "989     dr1    0.980107   990\n",
       "990   hoxa1    0.980110   991\n",
       "991  barhl1    0.981534   992\n",
       "\n",
       "[992 rows x 3 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "chrom_acc_similarity = [cosine_similarity(up_chrom_acc_embs[i].reshape(1, -1), nochange_chrom_acc_embs[i].reshape(1, -1))[0, 0] for i in range(up_chrom_acc_embs.shape[0])]\n",
    "chrom_acc_similarity_df = pd.DataFrame({'factors':names,'similarity':chrom_acc_similarity}).sort_values(by='similarity').reset_index(drop=True)\n",
    "chrom_acc_similarity_df['rank']=chrom_acc_similarity_df.index + 1\n",
    "chrom_acc_similarity_df.to_csv(f'{chromatin_accessibility_dir}/chromatin_accessibility_similarity_df.csv',index=False)\n",
    "chrom_acc_similarity_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>factors</th>\n",
       "      <th>similarity</th>\n",
       "      <th>rank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>myod1</td>\n",
       "      <td>0.038196</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  factors  similarity  rank\n",
       "0   myod1    0.038196     1"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chrom_acc_similarity_df[chrom_acc_similarity_df['factors']=='myod1']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We identified 25 key regulators in the chromatin accessibility, including the notable regulator 'MYOD1'."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combine the regulator rankings from both chromatin accessibility and transcriptome\n",
    "Final top 25 key regulators derived from average ranks across both chromatin accessibility and transcriptome."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>factors</th>\n",
       "      <th>similarity_gep</th>\n",
       "      <th>rank_gep</th>\n",
       "      <th>similarity_chrom_acc</th>\n",
       "      <th>rank_chrom_acc</th>\n",
       "      <th>averge_rank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>myod1</td>\n",
       "      <td>0.971539</td>\n",
       "      <td>18</td>\n",
       "      <td>0.038196</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   factors  similarity_gep  rank_gep  similarity_chrom_acc  rank_chrom_acc  \\\n",
       "17   myod1        0.971539        18              0.038196               1   \n",
       "\n",
       "    averge_rank  \n",
       "17            5  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gep_similarity_path = f'{chromatin_accessibility_dir}/../transcriptome/gep_similarity_df.csv'\n",
    "if not os.path.exists(gep_similarity_path):\n",
    "    raise ValueError(\"Please follow the tutorial for key regulators inference during cell state transition: Transcriptome\")\n",
    "else:\n",
    "    gep_similarity_df = pd.read_csv(gep_similarity_path)\n",
    "    average_rank_df = pd.merge(gep_similarity_df, chrom_acc_similarity_df, on='factors', how='inner', suffixes=('_gep', '_chrom_acc'))\n",
    "    average_rank_df['averge_rank'] = ((average_rank_df['rank_gep']+average_rank_df['rank_chrom_acc'])/2).rank().astype(int)\n",
    "    average_rank_df=average_rank_df.sort_values(by='averge_rank')\n",
    "    average_rank_df\n",
    "    \n",
    "average_rank_df[average_rank_df['factors']=='myod1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['myf5',\n",
       " 'dux4',\n",
       " 'nr3c2',\n",
       " 'tead1',\n",
       " 'myod1',\n",
       " 'chd4',\n",
       " 'neurog2',\n",
       " 'yap1',\n",
       " 'tead1, tead4',\n",
       " 'pgbd3',\n",
       " 'cbx6',\n",
       " 'six2',\n",
       " 'prox1',\n",
       " 'sumo1',\n",
       " 'cbx7',\n",
       " 'pgr',\n",
       " 'pax6',\n",
       " 'nr3c1',\n",
       " 'ring1',\n",
       " 'chrm2',\n",
       " 'rb1',\n",
       " 'klf15',\n",
       " 'tcf21',\n",
       " 'lhx2',\n",
       " 'tp53']"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_indentified_factor = average_rank_df[average_rank_df['averge_rank']<=25]['factors'].tolist()\n",
    "final_indentified_factor"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "demo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
