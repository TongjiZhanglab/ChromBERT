{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example for uncovers cellular dynamics using ChromBERT: Transcriptome\n",
    "To fully uncover cellular dynamics, it is essential to combine analyses of chromatin accessibility and the transcriptome. In this tutorial, we will demonstrate how to use ChromBERT to uncover cellular dynamics during a specific transdifferentiation process(Fibroblast to myoblast) in transcriptome. To follow this tutorial, you need to have the checkpoint (ckpt) files downloaded (see the README for details).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]='0'\n",
    "import chrombert\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from torchinfo import summary\n",
    "import subprocess\n",
    "import torch\n",
    "import lightning.pytorch as pl \n",
    "base_dir =  os.path.expanduser(\"~/.cache/chrombert/data\") ### to_path_chrombert/data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing transcriptome dataset\n",
    "You need to prepare transcriptome data (including TSS and TPM for gene).This tutorial will show you how to transform the data into the format required by ChromBERT.\n",
    "To fine-tune on transcriptome data for predicting log1p-transformed fold change during transdifferentiation, you need to prepare the log1p-transformed fold change data. Additionally, you need to obtain the ChromBERT 1kb region bins corresponding to the TSS of the relevant genes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(   chrom       tss          gene_id        tpm\n",
       " 0  chr19  58353492  ENSG00000121410  22.236894\n",
       " 1  chr19  58347718  ENSG00000268895   9.317134\n",
       " 2  chr10  50885675  ENSG00000148584   0.000000\n",
       " 3  chr12   9116229  ENSG00000175899   0.993828\n",
       " 4  chr12   9065163  ENSG00000245105   0.124228,\n",
       "    chrom       tss          gene_id        tpm\n",
       " 0  chr19  58353492  ENSG00000121410  12.774133\n",
       " 1  chr19  58347718  ENSG00000268895   2.939181\n",
       " 2  chr10  50885675  ENSG00000148584   0.000000\n",
       " 3  chr12   9116229  ENSG00000175899   0.226091\n",
       " 4  chr12   9065163  ENSG00000245105   0.226091)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gep_dir = f'{base_dir}/demo/transdifferentiation/transcriptome'\n",
    "fibroblast_exp = pd.read_csv(f'{gep_dir}/fibroblast_expression.csv')\n",
    "myoblast_exp = pd.read_csv(f'{gep_dir}/myoblast_expression.csv')\n",
    "myoblast_exp.head(), fibroblast_exp.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prepare the log1p-transformed fold change data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>chrom</th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "      <th>build_region_index</th>\n",
       "      <th>label</th>\n",
       "      <th>tss</th>\n",
       "      <th>gene_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>chr19</td>\n",
       "      <td>58353000</td>\n",
       "      <td>58354000</td>\n",
       "      <td>917950</td>\n",
       "      <td>0.522949</td>\n",
       "      <td>58353492</td>\n",
       "      <td>ENSG00000121410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>chr19</td>\n",
       "      <td>58347000</td>\n",
       "      <td>58348000</td>\n",
       "      <td>917944</td>\n",
       "      <td>0.962833</td>\n",
       "      <td>58347718</td>\n",
       "      <td>ENSG00000268895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>chr10</td>\n",
       "      <td>50885000</td>\n",
       "      <td>50886000</td>\n",
       "      <td>221904</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>50885675</td>\n",
       "      <td>ENSG00000148584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>chr12</td>\n",
       "      <td>9116000</td>\n",
       "      <td>9117000</td>\n",
       "      <td>393001</td>\n",
       "      <td>0.486225</td>\n",
       "      <td>9116229</td>\n",
       "      <td>ENSG00000175899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>chr12</td>\n",
       "      <td>9065000</td>\n",
       "      <td>9066000</td>\n",
       "      <td>392961</td>\n",
       "      <td>-0.086734</td>\n",
       "      <td>9065163</td>\n",
       "      <td>ENSG00000245105</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   chrom     start       end  build_region_index     label       tss  \\\n",
       "0  chr19  58353000  58354000              917950  0.522949  58353492   \n",
       "1  chr19  58347000  58348000              917944  0.962833  58347718   \n",
       "2  chr10  50885000  50886000              221904  0.000000  50885675   \n",
       "3  chr12   9116000   9117000              393001  0.486225   9116229   \n",
       "4  chr12   9065000   9066000              392961 -0.086734   9065163   \n",
       "\n",
       "           gene_id  \n",
       "0  ENSG00000121410  \n",
       "1  ENSG00000268895  \n",
       "2  ENSG00000148584  \n",
       "3  ENSG00000175899  \n",
       "4  ENSG00000245105  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from chrombert.scripts.chrombert_make_dataset import get_regions\n",
    "merge_exp = pd.merge(fibroblast_exp,myoblast_exp,left_on=['chrom','tss','gene_id'],right_on=['chrom','tss','gene_id'],suffixes=['_fibroblast','_myoblast'])\n",
    "merge_exp['fold_change']= np.log1p(merge_exp['tpm_myoblast']) - np.log1p(merge_exp['tpm_fibroblast'])\n",
    "merge_exp['start'] = merge_exp['tss']//1000 * 1000\n",
    "merge_exp['end'] = (merge_exp['tss']//1000 + 1) * 1000\n",
    "foldchange_exp = merge_exp [['chrom','start','end','tss','gene_id','fold_change']]\n",
    "\n",
    "chrom_regions = get_regions(base_dir,genome='hg38',high_resolution=False) # 1kb\n",
    "chrom_regions\n",
    "chrom_regions_df = pd.read_csv(chrom_regions,sep='\\t',names=['chrom','start','end','build_region_index'])\n",
    "chrom_regions_df\n",
    "merge_region = pd.merge(foldchange_exp,chrom_regions_df,left_on=['chrom','start','end'],right_on=['chrom','start','end'],how='inner')[['chrom','start','end','build_region_index','fold_change','tss','gene_id']]\n",
    "gep_df = merge_region.rename(columns={'fold_change':'label'})\n",
    "gep_df.to_csv(f'{gep_dir}/fibroblast_to_myoblast_expression_changes.csv',index=False)\n",
    "gep_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preprocessing the fine-tuning data of transcriptome \n",
    "splitting it into training, testing, and validation sets with an 8:1:1 ratio and Downsample the data to test the fine-tuning process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>chrom</th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "      <th>build_region_index</th>\n",
       "      <th>label</th>\n",
       "      <th>tss</th>\n",
       "      <th>gene_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4496</th>\n",
       "      <td>chr6</td>\n",
       "      <td>138795000</td>\n",
       "      <td>138796000</td>\n",
       "      <td>1719247</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>138795911</td>\n",
       "      <td>ENSG00000203734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13237</th>\n",
       "      <td>chr8</td>\n",
       "      <td>96261000</td>\n",
       "      <td>96262000</td>\n",
       "      <td>1933979</td>\n",
       "      <td>-0.351699</td>\n",
       "      <td>96261902</td>\n",
       "      <td>ENSG00000156471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17079</th>\n",
       "      <td>chr22</td>\n",
       "      <td>29555000</td>\n",
       "      <td>29556000</td>\n",
       "      <td>1186796</td>\n",
       "      <td>-0.565257</td>\n",
       "      <td>29555216</td>\n",
       "      <td>ENSG00000100296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4118</th>\n",
       "      <td>chr8</td>\n",
       "      <td>1622000</td>\n",
       "      <td>1623000</td>\n",
       "      <td>1866390</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1622417</td>\n",
       "      <td>ENSG00000253267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13482</th>\n",
       "      <td>chr7</td>\n",
       "      <td>66682000</td>\n",
       "      <td>66683000</td>\n",
       "      <td>1792879</td>\n",
       "      <td>0.402664</td>\n",
       "      <td>66682164</td>\n",
       "      <td>ENSG00000154710</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       chrom      start        end  build_region_index     label        tss  \\\n",
       "4496    chr6  138795000  138796000             1719247  0.000000  138795911   \n",
       "13237   chr8   96261000   96262000             1933979 -0.351699   96261902   \n",
       "17079  chr22   29555000   29556000             1186796 -0.565257   29555216   \n",
       "4118    chr8    1622000    1623000             1866390  0.000000    1622417   \n",
       "13482   chr7   66682000   66683000             1792879  0.402664   66682164   \n",
       "\n",
       "               gene_id  \n",
       "4496   ENSG00000203734  \n",
       "13237  ENSG00000156471  \n",
       "17079  ENSG00000100296  \n",
       "4118   ENSG00000253267  \n",
       "13482  ENSG00000154710  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data = gep_df.sample(frac=0.8,random_state=55)\n",
    "test_data = gep_df.drop(train_data.index).sample(frac=0.5,random_state=55)\n",
    "valid_data = gep_df.drop(train_data.index).drop(test_data.index)\n",
    "train_data_sample = train_data.sample(n=80,random_state=55)\n",
    "test_data_sample = test_data.sample(n=20,random_state=55)\n",
    "valid_data_sample = valid_data.sample(n=20,random_state=55)\n",
    "train_data_sample.to_csv(f'{gep_dir}/train_sample.csv',index=False)\n",
    "test_data_sample.to_csv(f'{gep_dir}/test_sample.csv',index=False)\n",
    "valid_data_sample.to_csv(f'{gep_dir}/valid_sample.csv',index=False)\n",
    "train_data_sample.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prepare the upregulated genes and unchanged genes for downstream analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "up_data = gep_df[gep_df['label']>1]\n",
    "nochange_data = gep_df[(gep_df['label']>-0.5) & (gep_df['label']<0.5)]\n",
    "\n",
    "up_data_sample = up_data.sample(n=100,random_state=55)\n",
    "nochange_data_sample = nochange_data.sample(n=100,random_state=55)\n",
    "\n",
    "\n",
    "up_data_sample.to_csv(f'{gep_dir}/up_data_sample.csv',index=False)\n",
    "nochange_data_sample.to_csv(f'{gep_dir}/nochange_data_sample.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fine-tune\n",
    "\n",
    "In this section, we provide a tutorial for fine-tuning ChromBERTs to predict genome-wide changes in transcriptome.\n",
    "However, the objectives for transcriptome changes differed due to the potential uncertainty in the influence of regions adjacent to transcription start sites (TSSs) on gene expression,  with a few key modifications:\n",
    "- Dataset config Preparation: We use the `multi_flank_window` preset dataset config and set four `flank_window` parameter\n",
    "- Model Instantiation: We use the `gep` preset model config and set four `gep_flank_window` parameter\n",
    "Let's get started!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set dataset config and data_module\n",
    "\n",
    "We use the `multi_flank_window` preset dataset config and set four `flank_window` parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "update path: hdf5_file = hg38_6k_1kb.hdf5\n",
      "update path: meta_file = config/hg38_6k_meta.json\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DatasetConfig({'hdf5_file': '/home/chenqianqian/.cache/chrombert/data/hg38_6k_1kb.hdf5', 'supervised_file': None, 'kind': 'MultiFlankwindowDataset', 'meta_file': '/home/chenqianqian/.cache/chrombert/data/config/hg38_6k_meta.json', 'ignore': False, 'ignore_object': None, 'batch_size': 4, 'num_workers': 4, 'shuffle': False, 'perturbation': False, 'perturbation_object': None, 'perturbation_value': 0, 'prompt_kind': None, 'prompt_regulator': None, 'prompt_regulator_cache_file': None, 'prompt_celltype': None, 'prompt_celltype_cache_file': None, 'fasta_file': None, 'flank_window': 4})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_config = chrombert.get_preset_dataset_config(\"multi_flank_window\",supervised_file = None, batch_size = 4, num_workers = 4,flank_window=4)\n",
    "dataset_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "gep_dir = f'{base_dir}/demo/transdifferentiation/transcriptome'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_module = chrombert.LitChromBERTFTDataModule(\n",
    "    config = dataset_config, \n",
    "    train_params = {'supervised_file': f'{gep_dir}/train_sample.csv'}, \n",
    "    val_params = {'supervised_file':f'{gep_dir}/valid_sample.csv'}, \n",
    "    test_params = {'supervised_file':f'{gep_dir}/test_sample.csv'}\n",
    ")\n",
    "data_module.setup()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set model config and model loading\n",
    "We use the `gep` preset model config and set four `gep_flank_window` parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "update path: mtx_mask = config/hg38_6k_mask_matrix.tsv\n",
      "update path: pretrain_ckpt = checkpoint/hg38_6k_1kb_pretrain.ckpt\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ChromBERTFTConfig(genome='hg38', task='gep', dim_output=1, mtx_mask='/home/chenqianqian/.cache/chrombert/data/config/hg38_6k_mask_matrix.tsv', dropout=0.1, pretrain_ckpt='/home/chenqianqian/.cache/chrombert/data/checkpoint/hg38_6k_1kb_pretrain.ckpt', finetune_ckpt=None, ignore=False, ignore_index=(None, None), gep_flank_window=4, gep_parallel_embedding=False, gep_gradient_checkpoint=False, gep_zero_inflation=True, prompt_kind='cistrome', prompt_dim_external=512, dnabert2_ckpt=None)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_config = chrombert.get_preset_model_config(\"gep\",gep_flank_window=4)\n",
    "model_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "use organisim hg38; max sequence length including cls is 6392\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "=====================================================================================\n",
       "Layer (type:depth-idx)                                       Param #\n",
       "=====================================================================================\n",
       "ChromBERTGEP                                                 --\n",
       "├─PoolFlankWindow: 1-1                                       --\n",
       "│    └─ChromBERT: 2-1                                        --\n",
       "│    │    └─BERTEmbedding: 3-1                               (4,916,736)\n",
       "│    │    └─ModuleList: 3-2                                  51,978,240\n",
       "├─GepHeader: 1-2                                             --\n",
       "│    └─CistromeEmbeddingManager: 2-2                         --\n",
       "│    └─Conv2d: 2-3                                           769\n",
       "│    └─ReLU: 2-4                                             --\n",
       "│    └─ResidualBlock: 2-5                                    --\n",
       "│    │    └─Linear: 3-3                                      1,090,560\n",
       "│    │    └─Linear: 3-4                                      1,049,600\n",
       "│    │    └─LayerNorm: 3-5                                   2,048\n",
       "│    │    └─Linear: 3-6                                      1,090,560\n",
       "│    │    └─Dropout: 3-7                                     --\n",
       "│    └─ResidualBlock: 2-6                                    --\n",
       "│    │    └─Linear: 3-8                                      787,200\n",
       "│    │    └─Linear: 3-9                                      590,592\n",
       "│    │    └─LayerNorm: 3-10                                  1,536\n",
       "│    │    └─Linear: 3-11                                     787,200\n",
       "│    │    └─Dropout: 3-12                                    --\n",
       "│    └─ResidualBlock: 2-7                                    --\n",
       "│    │    └─Linear: 3-13                                     196,864\n",
       "│    │    └─Linear: 3-14                                     65,792\n",
       "│    │    └─LayerNorm: 3-15                                  512\n",
       "│    │    └─Linear: 3-16                                     196,864\n",
       "│    │    └─Dropout: 3-17                                    --\n",
       "│    └─Sequential: 2-8                                       --\n",
       "│    │    └─Linear: 3-18                                     257\n",
       "│    └─Linear: 2-9                                           257\n",
       "=====================================================================================\n",
       "Total params: 62,755,587\n",
       "Trainable params: 18,855,171\n",
       "Non-trainable params: 43,900,416\n",
       "====================================================================================="
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = model_config.init_model()\n",
    "model.freeze_pretrain(2) ### freeze chrombert 6 transformer blocks\n",
    "summary(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set train config and finetune\n",
    "\n",
    "We fine-tune the model using PyTorch Lightning. A simple configuration is created to process parameters, and tuning is performed on a limited dataset to save time.\n",
    "Note: The tuning process is random, so results may vary. To achieve the best results, consider increasing the number of epochs and the size of the dataset used\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/chenqianqian/.conda/envs/demo/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: Metric `SpearmanCorrcoef` will save all targets and predictions in the buffer. For large datasets, this may lead to large memory footprint.\n",
      "  warnings.warn(*args, **kwargs)  # noqa: B028\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "chrombert.finetune.train.pl_module.ZeroInflationPLModule"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_config = chrombert.finetune.TrainConfig(kind='zero_inflation',        \n",
    "loss='zero_inflation',\n",
    "max_epochs=2,\n",
    "accumulate_grad_batches=2,\n",
    "val_check_interval=2,\n",
    "limit_val_batches=10,\n",
    "tag='gep')\n",
    "pl_module = train_config.init_pl_module(model) # wrap model with PyTorch Lightning module\n",
    "type(pl_module)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we start tuning!   \n",
    "The trainer will save logs in a format compatible with TensorBoard, and the checkpoint with the lowest validation loss will be saved during the process.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using bfloat16 Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "You are using a CUDA device ('NVIDIA A100-PCIE-40GB') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "\n",
      "  | Name  | Type         | Params | Mode \n",
      "-----------------------------------------------\n",
      "0 | model | ChromBERTGEP | 62.8 M | train\n",
      "-----------------------------------------------\n",
      "18.9 M    Trainable params\n",
      "43.9 M    Non-trainable params\n",
      "62.8 M    Total params\n",
      "251.022   Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "980b957b97e34b3e860bb39dfa8390ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/chenqianqian/.conda/envs/demo/lib/python3.9/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:475: Your `val_dataloader`'s sampler has shuffling enabled, it is strongly recommended that you turn shuffling off for val/test dataloaders.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bb979c1a0c9447dc84fb0b605f3ea369",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8bb9133a433943a1bdc513ac277bcbab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "09d080ee714b46aa88f008fc1ff33722",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4f2a9794d4c94267835b14fec086e080",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "35e9339c16294a1c90de1593925c1eb5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "edf4ddaa60e3477bb0af178dd4eb2747",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c355264e52774270ac2e568200c8f0c4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "892f2bc8404f41b7b615040b6255e657",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e99d62ae5c4d4c9787648a158375f46c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c4c291ab3fa4eb5a709705fc61f639d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "00f5d263b7c04a2a97370a7f46a5f2a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "41f740517280409e8b863badfe2ef55b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0ee799353cd84fc3a90ff3540cec7778",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a744ed0df0e46ba9dddf77a2961b80f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "74b8ec87a7e344b8ac50ad155a1d16cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7cefbd779c07480fab2d981d94ef710b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eb835f10da4c461b8435833e8487463e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "90f3d8fc7f644767ad32433654651cc5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "92d9aa3319e04a4eb38d9099d0ffdfdf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "832f9cfdef09444eaf8825ab6ce2aa2d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b77a78613cc943e78168ba7b7b129243",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=2` reached.\n"
     ]
    }
   ],
   "source": [
    "callback_ckpt = pl.callbacks.ModelCheckpoint(monitor = f\"{train_config.tag}_validation/{train_config.loss}\", mode = \"min\")\n",
    "trainer = pl.Trainer(\n",
    "    max_epochs=train_config.max_epochs,\n",
    "    log_every_n_steps=1, \n",
    "    limit_val_batches = train_config.limit_val_batches,\n",
    "    val_check_interval = train_config.val_check_interval,\n",
    "    accelerator=\"gpu\", \n",
    "    accumulate_grad_batches= train_config.accumulate_grad_batches, \n",
    "    fast_dev_run=False, \n",
    "    precision=\"bf16-mixed\",\n",
    "    strategy=\"auto\",\n",
    "    callbacks=[\n",
    "        pl.callbacks.LearningRateMonitor(),\n",
    "        callback_ckpt,   \n",
    "    ],\n",
    "    logger=pl.loggers.TensorBoardLogger(\"lightning_logs\", name='gep'))\n",
    "trainer.fit(pl_module,data_module)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load fine-tuned checkpoint and evaluation\n",
    "ChromBERT is now fine-tuned! You can access the tuned model directly using `pl_module.model`. However, please note that due to specific settings in flash-attention, you cannot change the dropout probability, which may introduce some randomness in the output.\n",
    "\n",
    "For consistent results, we recommend saving the checkpoint and loading it with the original model to ensure you have the tuned model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load limited fine-tuned checkpoint of predicting genome-wide changes in transcriptome \n",
    "Due to time constraints in tutorial, we only use downsampled test data for evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/shared/chenqianqian/data_copy1/chenqianqian/finetune/test_model/ChromBERT_public/examples/tutorials/lightning_logs/gep/version_0/checkpoints/epoch=1-step=14.ckpt\n",
      "update path: mtx_mask = config/hg38_6k_mask_matrix.tsv\n",
      "update path: pretrain_ckpt = checkpoint/hg38_6k_1kb_pretrain.ckpt\n",
      "use organisim hg38; max sequence length including cls is 6392\n",
      "Loading checkpoint from /shared/chenqianqian/data_copy1/chenqianqian/finetune/test_model/ChromBERT_public/examples/tutorials/lightning_logs/gep/version_0/checkpoints/epoch=1-step=14.ckpt\n",
      "Loading from pl module, remove prefix 'model.'\n",
      "Loaded 112/112 parameters\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "=====================================================================================\n",
       "Layer (type:depth-idx)                                       Param #\n",
       "=====================================================================================\n",
       "ChromBERTGEP                                                 --\n",
       "├─PoolFlankWindow: 1-1                                       --\n",
       "│    └─ChromBERT: 2-1                                        --\n",
       "│    │    └─BERTEmbedding: 3-1                               4,916,736\n",
       "│    │    └─ModuleList: 3-2                                  51,978,240\n",
       "├─GepHeader: 1-2                                             --\n",
       "│    └─CistromeEmbeddingManager: 2-2                         --\n",
       "│    └─Conv2d: 2-3                                           769\n",
       "│    └─ReLU: 2-4                                             --\n",
       "│    └─ResidualBlock: 2-5                                    --\n",
       "│    │    └─Linear: 3-3                                      1,090,560\n",
       "│    │    └─Linear: 3-4                                      1,049,600\n",
       "│    │    └─LayerNorm: 3-5                                   2,048\n",
       "│    │    └─Linear: 3-6                                      1,090,560\n",
       "│    │    └─Dropout: 3-7                                     --\n",
       "│    └─ResidualBlock: 2-6                                    --\n",
       "│    │    └─Linear: 3-8                                      787,200\n",
       "│    │    └─Linear: 3-9                                      590,592\n",
       "│    │    └─LayerNorm: 3-10                                  1,536\n",
       "│    │    └─Linear: 3-11                                     787,200\n",
       "│    │    └─Dropout: 3-12                                    --\n",
       "│    └─ResidualBlock: 2-7                                    --\n",
       "│    │    └─Linear: 3-13                                     196,864\n",
       "│    │    └─Linear: 3-14                                     65,792\n",
       "│    │    └─LayerNorm: 3-15                                  512\n",
       "│    │    └─Linear: 3-16                                     196,864\n",
       "│    │    └─Dropout: 3-17                                    --\n",
       "│    └─Sequential: 2-8                                       --\n",
       "│    │    └─Linear: 3-18                                     257\n",
       "│    └─Linear: 2-9                                           257\n",
       "=====================================================================================\n",
       "Total params: 62,755,587\n",
       "Trainable params: 62,755,587\n",
       "Non-trainable params: 0\n",
       "====================================================================================="
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import glob\n",
    "gep_ft_ckpt = os.path.abspath(glob.glob('./lightning_logs/gep/version_0/checkpoints/*.ckpt')[0])\n",
    "print(gep_ft_ckpt)\n",
    "\n",
    "model_config = chrombert.get_preset_model_config(\"gep\",gep_flank_window=4, dropout=0)\n",
    "ft_model = model_config.init_model(finetune_ckpt = gep_ft_ckpt)\n",
    "summary(ft_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:09<00:00,  1.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'pearsonr': tensor(-0.0313), 'spearmanr': tensor(0.1015), 'mse': tensor(0.4036), 'mae': tensor(0.5084), 'r2': tensor(-1.1500)}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "/home/chenqianqian/.conda/envs/demo/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: Metric `SpearmanCorrcoef` will save all targets and predictions in the buffer. For large datasets, this may lead to large memory footprint.\n",
      "  warnings.warn(*args, **kwargs)  # noqa: B028\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "import torchmetrics as tm\n",
    "dl = data_module.test_dataloader()\n",
    "ft_model.cuda()\n",
    "with torch.no_grad():\n",
    "    y_preds = []\n",
    "    y_labels = []\n",
    "    for idx, batch in enumerate(tqdm(dl, total=len(dl))):\n",
    "        for k in batch:\n",
    "            if isinstance(batch[k], torch.Tensor):\n",
    "                batch[k] = batch[k].cuda()\n",
    "        y_pred = ft_model(batch)[1].cpu()\n",
    "        y_label = batch['label'].cpu()\n",
    "        y_preds.append(y_pred)\n",
    "        y_labels.append(y_label)\n",
    "    y_preds = torch.cat(y_preds)\n",
    "    y_labels = torch.cat(y_labels)\n",
    "predicts = y_preds.view(-1)\n",
    "labels = y_labels.view(-1)\n",
    "metrics_pearsonr = tm.PearsonCorrCoef()\n",
    "metrics_spearmanr = tm.SpearmanCorrCoef()\n",
    "metrics_mse = tm.MeanSquaredError()\n",
    "metrics_mae = tm.MeanAbsoluteError()\n",
    "metrics_r2 = tm.R2Score()\n",
    "score_pearsonr = metrics_pearsonr(predicts, labels)\n",
    "score_spearmanr = metrics_spearmanr(predicts, labels)\n",
    "score_mse = metrics_mse(predicts, labels)\n",
    "score_mae = metrics_mae(predicts, labels)\n",
    "score_r2 = metrics_r2(predicts, labels)\n",
    "scores = {\n",
    "    \"pearsonr\": score_pearsonr,\n",
    "    \"spearmanr\": score_spearmanr,\n",
    "    \"mse\": score_mse,\n",
    "    \"mae\": score_mae,\n",
    "    \"r2\": score_r2,\n",
    "    }\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load the checkpoint using the entire dataset to fine-tune for predicting genome-wide changes in the transcriptome\n",
    "Using a limited fine-tuned checkpoint results in poor evaluation performance. We have fine-tuned a checkpoint using the entire dataset to enhance its performance for predicting genome-wide changes in the transcriptome. Due to time constraints in tutorial, we only use downsampled test data for evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "update path: mtx_mask = config/hg38_6k_mask_matrix.tsv\n",
      "update path: pretrain_ckpt = checkpoint/hg38_6k_1kb_pretrain.ckpt\n",
      "use organisim hg38; max sequence length including cls is 6392\n",
      "Loading checkpoint from /home/chenqianqian/.cache/chrombert/data/demo/transdifferentiation/transcriptome/gep_fibroblast_to_myoblast.ckpt\n",
      "Loaded 112/112 parameters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:08<00:00,  1.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'pearsonr': tensor(0.4961), 'spearmanr': tensor(0.4652), 'mse': tensor(0.1490), 'mae': tensor(0.3108), 'r2': tensor(0.2062)}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "/home/chenqianqian/.conda/envs/demo/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: Metric `SpearmanCorrcoef` will save all targets and predictions in the buffer. For large datasets, this may lead to large memory footprint.\n",
      "  warnings.warn(*args, **kwargs)  # noqa: B028\n"
     ]
    }
   ],
   "source": [
    "gep_ft_ckpt = f'{gep_dir}/gep_fibroblast_to_myoblast.ckpt'\n",
    "\n",
    "model_config = chrombert.get_preset_model_config(\"gep\",gep_flank_window=4, dropout=0)\n",
    "ft_model = model_config.init_model(finetune_ckpt = gep_ft_ckpt)\n",
    "\n",
    "dl = data_module.test_dataloader()\n",
    "ft_model.cuda()\n",
    "with torch.no_grad():\n",
    "    y_preds = []\n",
    "    y_labels = []\n",
    "    for batch in tqdm(dl,total=len(dl)):\n",
    "        for k in batch:\n",
    "            if isinstance(batch[k], torch.Tensor):\n",
    "                batch[k] = batch[k].cuda()\n",
    "        y_pred = ft_model(batch)[1].cpu()\n",
    "        y_label = batch['label'].cpu()\n",
    "        y_preds.append(y_pred)\n",
    "        y_labels.append(y_label)\n",
    "    y_preds = torch.cat(y_preds)\n",
    "    y_labels = torch.cat(y_labels)\n",
    "predicts = y_preds.view(-1)\n",
    "labels = y_labels.view(-1)\n",
    "metrics_pearsonr = tm.PearsonCorrCoef()\n",
    "metrics_spearmanr = tm.SpearmanCorrCoef()\n",
    "metrics_mse = tm.MeanSquaredError()\n",
    "metrics_mae = tm.MeanAbsoluteError()\n",
    "metrics_r2 = tm.R2Score()\n",
    "score_pearsonr = metrics_pearsonr(predicts, labels)\n",
    "score_spearmanr = metrics_spearmanr(predicts, labels)\n",
    "score_mse = metrics_mse(predicts, labels)\n",
    "score_mae = metrics_mae(predicts, labels)\n",
    "score_r2 = metrics_r2(predicts, labels)\n",
    "scores = {\n",
    "    \"pearsonr\": score_pearsonr,\n",
    "    \"spearmanr\": score_spearmanr,\n",
    "    \"mse\": score_mse,\n",
    "    \"mae\": score_mae,\n",
    "    \"r2\": score_r2,\n",
    "    }\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use tuned to get regulator embedding and identified key regulator in cell state transition\n",
    "\n",
    "Using a limited fine-tuned checkpoint results in poor evaluation performance; We have fine-tuned a checkpoint using the entire dataset to enhance its performance for predicting genome-wide changes in the transcriptome. Now, to obtain regulator embeddings, we load this fine-tuned checkpoint. However, due to time constraints in the tutorial, we will only use downsampled data for evaluation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "update path: mtx_mask = config/hg38_6k_mask_matrix.tsv\n",
      "update path: pretrain_ckpt = checkpoint/hg38_6k_1kb_pretrain.ckpt\n",
      "update path: finetune_ckpt = /home/chenqianqian/.cache/chrombert/data/demo/transdifferentiation/transcriptome/gep_fibroblast_to_myoblast.ckpt\n",
      "use organisim hg38; max sequence length including cls is 6392\n",
      "Loading checkpoint from /home/chenqianqian/.cache/chrombert/data/demo/transdifferentiation/transcriptome/gep_fibroblast_to_myoblast.ckpt\n",
      "Loaded 112/112 parameters\n"
     ]
    }
   ],
   "source": [
    "model_tuned = chrombert.get_preset_model_config(\n",
    "    \"gep\", \n",
    "    gep_flank_window = 4,\n",
    "    dropout = 0,\n",
    "    finetune_ckpt = f'{gep_dir}/gep_fibroblast_to_myoblast.ckpt').init_model() # use absolute path here, to avoid mixing of preset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "=====================================================================================\n",
       "Layer (type:depth-idx)                                       Param #\n",
       "=====================================================================================\n",
       "ChromBERTEmbedding                                           --\n",
       "├─PoolFlankWindow: 1-1                                       --\n",
       "│    └─ChromBERT: 2-1                                        --\n",
       "│    │    └─BERTEmbedding: 3-1                               4,916,736\n",
       "│    │    └─ModuleList: 3-2                                  51,978,240\n",
       "├─CistromeEmbeddingManager: 1-2                              --\n",
       "=====================================================================================\n",
       "Total params: 56,894,976\n",
       "Trainable params: 56,894,976\n",
       "Non-trainable params: 0\n",
       "====================================================================================="
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_emb = model_tuned.get_embedding_manager().cuda()\n",
    "summary(model_emb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "update path: hdf5_file = hg38_6k_1kb.hdf5\n",
      "update path: meta_file = config/hg38_6k_meta.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:43<00:00, 10.98s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([100, 1064, 768])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_config = chrombert.get_preset_dataset_config(\"multi_flank_window\",supervised_file = f'{gep_dir}/up_data_sample.csv', batch_size = 32, num_workers = 4)\n",
    "dl = dataset_config.init_dataloader()\n",
    "up_gep_embs = []\n",
    "for batch in tqdm(dl):\n",
    "    with torch.no_grad():\n",
    "        for k, v in batch.items():\n",
    "            if isinstance(v, torch.Tensor):\n",
    "                batch[k] = v.cuda()\n",
    "        emb = model_emb(batch).cpu()\n",
    "        up_gep_embs.append(emb)\n",
    "up_gep_embs = torch.cat(up_gep_embs)\n",
    "up_gep_embs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "update path: hdf5_file = hg38_6k_1kb.hdf5\n",
      "update path: meta_file = config/hg38_6k_meta.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:44<00:00, 11.12s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([100, 1064, 768])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_config = chrombert.get_preset_dataset_config(\"multi_flank_window\",supervised_file = f'{gep_dir}/nochange_data_sample.csv', batch_size = 32, num_workers = 4)\n",
    "dl = dataset_config.init_dataloader()\n",
    "nochange_gep_embs = []\n",
    "for batch in tqdm(dl):\n",
    "    with torch.no_grad():\n",
    "        for k, v in batch.items():\n",
    "            if isinstance(v, torch.Tensor):\n",
    "                batch[k] = v.cuda()\n",
    "        emb = model_emb(batch).cpu()\n",
    "        nochange_gep_embs.append(emb)\n",
    "nochange_gep_embs = torch.cat(nochange_gep_embs)\n",
    "nochange_gep_embs.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We consider only factors below, remove histone modifications and chromatin accessibility. Then we can get similarity between factors, which represent the potential interactions between factors. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(base_dir, \"config\",\"hg38_6k_factors_list.txt\"),\"r\") as f:\n",
    "    factors = f.read().strip().split(\"\\n\")\n",
    "factors = [f.strip().lower() for f in factors]\n",
    "\n",
    "\n",
    "indices = np.in1d(model_emb.list_regulator,factors)\n",
    "names = np.array(model_emb.list_regulator)[indices]\n",
    "up_gep_embs = up_gep_embs.mean(axis=0)[indices]\n",
    "nochange_gep_embs = nochange_gep_embs.mean(axis=0)[indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([996, 768]), torch.Size([996, 768]))"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "up_gep_embs.shape, nochange_gep_embs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>factors</th>\n",
       "      <th>similarity</th>\n",
       "      <th>rank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>rpe</td>\n",
       "      <td>0.902802</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>klf15</td>\n",
       "      <td>0.925641</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>nr3c2</td>\n",
       "      <td>0.926707</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>myf5</td>\n",
       "      <td>0.938897</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>pgr</td>\n",
       "      <td>0.950597</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>991</th>\n",
       "      <td>dbp</td>\n",
       "      <td>0.998239</td>\n",
       "      <td>992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>992</th>\n",
       "      <td>tfcp2</td>\n",
       "      <td>0.998259</td>\n",
       "      <td>993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>993</th>\n",
       "      <td>mafk</td>\n",
       "      <td>0.998279</td>\n",
       "      <td>994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>994</th>\n",
       "      <td>tfam</td>\n",
       "      <td>0.998362</td>\n",
       "      <td>995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>maff</td>\n",
       "      <td>0.998379</td>\n",
       "      <td>996</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>996 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    factors  similarity  rank\n",
       "0       rpe    0.902802     1\n",
       "1     klf15    0.925641     2\n",
       "2     nr3c2    0.926707     3\n",
       "3      myf5    0.938897     4\n",
       "4       pgr    0.950597     5\n",
       "..      ...         ...   ...\n",
       "991     dbp    0.998239   992\n",
       "992   tfcp2    0.998259   993\n",
       "993    mafk    0.998279   994\n",
       "994    tfam    0.998362   995\n",
       "995    maff    0.998379   996\n",
       "\n",
       "[996 rows x 3 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "gep_similarity = [cosine_similarity(up_gep_embs[i].reshape(1, -1), nochange_gep_embs[i].reshape(1, -1))[0, 0] for i in range(up_gep_embs.shape[0])]\n",
    "gep_similarity_df = pd.DataFrame({'factors':names,'similarity':gep_similarity}).sort_values(by='similarity').reset_index(drop=True)\n",
    "gep_similarity_df['rank']=gep_similarity_df.index + 1\n",
    "gep_similarity_df.to_csv(f'{gep_dir}/gep_similarity_df.csv',index=False)\n",
    "gep_similarity_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>factors</th>\n",
       "      <th>similarity</th>\n",
       "      <th>rank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>myod1</td>\n",
       "      <td>0.971539</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   factors  similarity  rank\n",
       "17   myod1    0.971539    18"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gep_similarity_df[gep_similarity_df['factors']=='myod1']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The average ranking is derived from the two modalities: chromatin accessibility and the transcriptome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>factors</th>\n",
       "      <th>similarity_gep</th>\n",
       "      <th>rank_gep</th>\n",
       "      <th>similarity_chrom_acc</th>\n",
       "      <th>rank_chrom_acc</th>\n",
       "      <th>averge_rank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>myod1</td>\n",
       "      <td>0.971539</td>\n",
       "      <td>18</td>\n",
       "      <td>0.038196</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   factors  similarity_gep  rank_gep  similarity_chrom_acc  rank_chrom_acc  \\\n",
       "17   myod1        0.971539        18              0.038196               1   \n",
       "\n",
       "    averge_rank  \n",
       "17            5  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chrom_accessibility_path = f'{gep_dir}/../chrom_accessibility/chromatin_accessibility_similarity_df.csv'\n",
    "if not os.path.exists(chrom_accessibility_path):\n",
    "    raise ValueError(\"Please follow the chromatin accessibility transdifferentiation tutorial to rank the regulatory factors within this context\")\n",
    "else:\n",
    "    chrom_acc_similarity_df = pd.read_csv(chrom_accessibility_path)\n",
    "    average_rank_df = pd.merge(gep_similarity_df, chrom_acc_similarity_df, on='factors', how='inner', suffixes=('_gep', '_chrom_acc'))\n",
    "    average_rank_df['averge_rank'] = ((average_rank_df['rank_gep']+average_rank_df['rank_chrom_acc'])/2).rank().astype(int)\n",
    "    average_rank_df=average_rank_df.sort_values(by='averge_rank')\n",
    "    average_rank_df\n",
    "    \n",
    "average_rank_df[average_rank_df['factors']=='myod1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "demo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
