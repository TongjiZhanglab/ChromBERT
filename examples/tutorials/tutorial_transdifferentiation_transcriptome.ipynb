{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example for key regulators inference during cell state transition: transcriptome\n",
    "\n",
    "To comprehensively infer key regulators during cell state transitions, it is crucial to integrate analyses of chromatin accessibility and the transcriptome. In this tutorial, we will demonstrate how to use ChromBERT to infer key regulators involved in a specific transdifferentiation process (fibroblast to myoblast) through transcriptome analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]='0'\n",
    "import chrombert\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from torchinfo import summary\n",
    "import subprocess\n",
    "import torch\n",
    "import lightning.pytorch as pl\n",
    "import glob\n",
    "from tqdm import tqdm\n",
    "import torchmetrics as tm \n",
    "base_dir =  os.path.expanduser(\"~/.cache/chrombert/data\") ### to_path_chrombert/data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess dataset  \n",
    "\n",
    "This section walks you through preparing raw transcriptome data, including TSS and TPM values for each gene, and transforming it into the format required by ChromBERT.  \n",
    "\n",
    "To identify key regulators, we will fine-tune ChromBERT to predict log1p-transformed gene expression fold changes during transdifferentiation. This requires careful preparation of the transformed data. Additionally, to analyze shifts in regulator embeddings, we need to identify and prepare datasets for both upregulated and unchanged genes.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(   chrom       tss          gene_id        tpm\n",
       " 0  chr19  58353492  ENSG00000121410  22.236894\n",
       " 1  chr19  58347718  ENSG00000268895   9.317134\n",
       " 2  chr10  50885675  ENSG00000148584   0.000000\n",
       " 3  chr12   9116229  ENSG00000175899   0.993828\n",
       " 4  chr12   9065163  ENSG00000245105   0.124228,\n",
       "    chrom       tss          gene_id        tpm\n",
       " 0  chr19  58353492  ENSG00000121410  12.774133\n",
       " 1  chr19  58347718  ENSG00000268895   2.939181\n",
       " 2  chr10  50885675  ENSG00000148584   0.000000\n",
       " 3  chr12   9116229  ENSG00000175899   0.226091\n",
       " 4  chr12   9065163  ENSG00000245105   0.226091)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We provide tables of gene expression data for fibroblast and myoblast.\n",
    "gep_dir = f'{base_dir}/demo/transdifferentiation/transcriptome'\n",
    "fibroblast_exp = pd.read_csv(f'{gep_dir}/fibroblast_expression.csv')\n",
    "myoblast_exp = pd.read_csv(f'{gep_dir}/myoblast_expression.csv')\n",
    "myoblast_exp.head(), fibroblast_exp.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare the log1p-transformed gene expression fold changes data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>chrom</th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "      <th>build_region_index</th>\n",
       "      <th>label</th>\n",
       "      <th>tss</th>\n",
       "      <th>gene_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>chr19</td>\n",
       "      <td>58353000</td>\n",
       "      <td>58354000</td>\n",
       "      <td>917950</td>\n",
       "      <td>0.522949</td>\n",
       "      <td>58353492</td>\n",
       "      <td>ENSG00000121410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>chr19</td>\n",
       "      <td>58347000</td>\n",
       "      <td>58348000</td>\n",
       "      <td>917944</td>\n",
       "      <td>0.962833</td>\n",
       "      <td>58347718</td>\n",
       "      <td>ENSG00000268895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>chr10</td>\n",
       "      <td>50885000</td>\n",
       "      <td>50886000</td>\n",
       "      <td>221904</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>50885675</td>\n",
       "      <td>ENSG00000148584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>chr12</td>\n",
       "      <td>9116000</td>\n",
       "      <td>9117000</td>\n",
       "      <td>393001</td>\n",
       "      <td>0.486225</td>\n",
       "      <td>9116229</td>\n",
       "      <td>ENSG00000175899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>chr12</td>\n",
       "      <td>9065000</td>\n",
       "      <td>9066000</td>\n",
       "      <td>392961</td>\n",
       "      <td>-0.086734</td>\n",
       "      <td>9065163</td>\n",
       "      <td>ENSG00000245105</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   chrom     start       end  build_region_index     label       tss  \\\n",
       "0  chr19  58353000  58354000              917950  0.522949  58353492   \n",
       "1  chr19  58347000  58348000              917944  0.962833  58347718   \n",
       "2  chr10  50885000  50886000              221904  0.000000  50885675   \n",
       "3  chr12   9116000   9117000              393001  0.486225   9116229   \n",
       "4  chr12   9065000   9066000              392961 -0.086734   9065163   \n",
       "\n",
       "           gene_id  \n",
       "0  ENSG00000121410  \n",
       "1  ENSG00000268895  \n",
       "2  ENSG00000148584  \n",
       "3  ENSG00000175899  \n",
       "4  ENSG00000245105  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from chrombert.scripts.chrombert_make_dataset import get_regions\n",
    "# We merge the two datasets, and calculate the log1p-transformed gene expression fold changes.\n",
    "merge_exp = pd.merge(fibroblast_exp,myoblast_exp,left_on=['chrom','tss','gene_id'],right_on=['chrom','tss','gene_id'],suffixes=['_fibroblast','_myoblast'])\n",
    "merge_exp['fold_change']= np.log1p(merge_exp['tpm_myoblast']) - np.log1p(merge_exp['tpm_fibroblast'])\n",
    "merge_exp['start'] = merge_exp['tss']//1000 * 1000\n",
    "merge_exp['end'] = (merge_exp['tss']//1000 + 1) * 1000\n",
    "foldchange_exp = merge_exp [['chrom','start','end','tss','gene_id','fold_change']]\n",
    "\n",
    "# align genomic coordinates to the predefined 1-kb bins\n",
    "chrom_regions = get_regions(base_dir,genome='hg38',high_resolution=False) # 1kb\n",
    "chrom_regions\n",
    "chrom_regions_df = pd.read_csv(chrom_regions,sep='\\t',names=['chrom','start','end','build_region_index'])\n",
    "chrom_regions_df\n",
    "merge_region = pd.merge(foldchange_exp,chrom_regions_df,left_on=['chrom','start','end'],right_on=['chrom','start','end'],how='inner')[['chrom','start','end','build_region_index','fold_change','tss','gene_id']]\n",
    "gep_df = merge_region.rename(columns={'fold_change':'label'})\n",
    "gep_df.to_csv(f'{gep_dir}/fibroblast_to_myoblast_expression_changes.csv',index=False)\n",
    "gep_df.head() ### This label represents log1p-transformed gene expression fold change data.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare the fine-tuning data\n",
    "We split the data into training, testing, and validation sets with an 8:1:1 ratio and downsample the data to test the fine-tuning process.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>chrom</th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "      <th>build_region_index</th>\n",
       "      <th>label</th>\n",
       "      <th>tss</th>\n",
       "      <th>gene_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4496</th>\n",
       "      <td>chr6</td>\n",
       "      <td>138795000</td>\n",
       "      <td>138796000</td>\n",
       "      <td>1719247</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>138795911</td>\n",
       "      <td>ENSG00000203734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13237</th>\n",
       "      <td>chr8</td>\n",
       "      <td>96261000</td>\n",
       "      <td>96262000</td>\n",
       "      <td>1933979</td>\n",
       "      <td>-0.351699</td>\n",
       "      <td>96261902</td>\n",
       "      <td>ENSG00000156471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17079</th>\n",
       "      <td>chr22</td>\n",
       "      <td>29555000</td>\n",
       "      <td>29556000</td>\n",
       "      <td>1186796</td>\n",
       "      <td>-0.565257</td>\n",
       "      <td>29555216</td>\n",
       "      <td>ENSG00000100296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4118</th>\n",
       "      <td>chr8</td>\n",
       "      <td>1622000</td>\n",
       "      <td>1623000</td>\n",
       "      <td>1866390</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1622417</td>\n",
       "      <td>ENSG00000253267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13482</th>\n",
       "      <td>chr7</td>\n",
       "      <td>66682000</td>\n",
       "      <td>66683000</td>\n",
       "      <td>1792879</td>\n",
       "      <td>0.402664</td>\n",
       "      <td>66682164</td>\n",
       "      <td>ENSG00000154710</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       chrom      start        end  build_region_index     label        tss  \\\n",
       "4496    chr6  138795000  138796000             1719247  0.000000  138795911   \n",
       "13237   chr8   96261000   96262000             1933979 -0.351699   96261902   \n",
       "17079  chr22   29555000   29556000             1186796 -0.565257   29555216   \n",
       "4118    chr8    1622000    1623000             1866390  0.000000    1622417   \n",
       "13482   chr7   66682000   66683000             1792879  0.402664   66682164   \n",
       "\n",
       "               gene_id  \n",
       "4496   ENSG00000203734  \n",
       "13237  ENSG00000156471  \n",
       "17079  ENSG00000100296  \n",
       "4118   ENSG00000253267  \n",
       "13482  ENSG00000154710  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data = gep_df.sample(frac=0.8,random_state=55)\n",
    "test_data = gep_df.drop(train_data.index).sample(frac=0.5,random_state=55)\n",
    "valid_data = gep_df.drop(train_data.index).drop(test_data.index)\n",
    "train_data_sample = train_data.sample(n=80,random_state=55)\n",
    "test_data_sample = test_data.sample(n=50,random_state=55)\n",
    "valid_data_sample = valid_data.sample(n=20,random_state=55)\n",
    "train_data_sample.to_csv(f'{gep_dir}/train_sample.csv',index=False)\n",
    "test_data_sample.to_csv(f'{gep_dir}/test_sample.csv',index=False)\n",
    "valid_data_sample.to_csv(f'{gep_dir}/valid_sample.csv',index=False)\n",
    "train_data_sample.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare the upregulated genes and unchanged genes\n",
    "Here we identify the upregulated genes and unchanged genes, based on the log1p-transformed gene expression fold changes.\n",
    "In addition, we downsample the list of upregulated and unchanged genes to save time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "up_data = gep_df[gep_df['label']>1]\n",
    "nochange_data = gep_df[(gep_df['label']>-0.5) & (gep_df['label']<0.5)]\n",
    "\n",
    "up_data_sample = up_data.sample(n=100,random_state=55)\n",
    "nochange_data_sample = nochange_data.sample(n=100,random_state=55)\n",
    "\n",
    "\n",
    "up_data_sample.to_csv(f'{gep_dir}/up_data_sample.csv',index=False)\n",
    "nochange_data_sample.to_csv(f'{gep_dir}/nochange_data_sample.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fine-tune  \n",
    "\n",
    "This section provides a tutorial for fine-tuning ChromBERTs to predict genome-wide changes in the transcriptome. The parameters for transcriptome changes are adjusted to account for the inclusion of nearby flank regions for each TSS. The process involves the following key modifications:  \n",
    "\n",
    "- **Dataset Configuration:** Use the `multi_flank_window` preset for dataset configuration and set the `flank_window` parameter to four.  \n",
    "- **Model Instantiation:** Use the `gep` preset for model configuration and set the `gep_flank_window` parameter to four.  \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configure dataset and data module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "update path: hdf5_file = hg38_6k_1kb.hdf5\n",
      "update path: meta_file = config/hg38_6k_meta.json\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DatasetConfig({'hdf5_file': '/home/chenqianqian/.cache/chrombert/data/hg38_6k_1kb.hdf5', 'supervised_file': None, 'kind': 'MultiFlankwindowDataset', 'meta_file': '/home/chenqianqian/.cache/chrombert/data/config/hg38_6k_meta.json', 'ignore': False, 'ignore_object': None, 'batch_size': 2, 'num_workers': 4, 'shuffle': False, 'pin_memory': True, 'perturbation': False, 'perturbation_object': None, 'perturbation_value': 0, 'prompt_kind': None, 'prompt_regulator': None, 'prompt_regulator_cache_file': None, 'prompt_celltype': None, 'prompt_celltype_cache_file': None, 'prompt_regulator_cache_pin_memory': False, 'prompt_regulator_cache_limit': 3, 'fasta_file': None, 'flank_window': 4})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We use the `multi_flank_window` preset dataset config and set the `flank_window` parameter to 4.\n",
    "# The flank_window parameter is used to set the flank window for the dataset configuration. \n",
    "# \"4\" represents +/- 4 nearest genomic regions to the TSS were used.\n",
    "dataset_config = chrombert.get_preset_dataset_config(\n",
    "    \"multi_flank_window\",\n",
    "    supervised_file = None, \n",
    "    batch_size = 2, \n",
    "    num_workers = 4,\n",
    "    flank_window=4 \n",
    "    )\n",
    "dataset_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "gep_dir = f'{base_dir}/demo/transdifferentiation/transcriptome'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We use the `LitChromBERTFTDataModule` to create a data module for fine-tuning.\n",
    "data_module = chrombert.LitChromBERTFTDataModule(\n",
    "    config = dataset_config, \n",
    "    train_params = {'supervised_file': f'{gep_dir}/train_sample.csv'}, \n",
    "    val_params = {'supervised_file':f'{gep_dir}/valid_sample.csv'}, \n",
    "    test_params = {'supervised_file':f'{gep_dir}/test_sample.csv'}\n",
    ")\n",
    "data_module.setup()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configure model and instantiation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "update path: mtx_mask = config/hg38_6k_mask_matrix.tsv\n",
      "update path: pretrain_ckpt = checkpoint/hg38_6k_1kb_pretrain.ckpt\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ChromBERTFTConfig:\n",
       "{\n",
       "    \"genome\": \"hg38\",\n",
       "    \"task\": \"gep\",\n",
       "    \"dim_output\": 1,\n",
       "    \"mtx_mask\": \"/home/chenqianqian/.cache/chrombert/data/config/hg38_6k_mask_matrix.tsv\",\n",
       "    \"dropout\": 0.1,\n",
       "    \"pretrain_ckpt\": \"/home/chenqianqian/.cache/chrombert/data/checkpoint/hg38_6k_1kb_pretrain.ckpt\",\n",
       "    \"finetune_ckpt\": null,\n",
       "    \"ignore\": false,\n",
       "    \"ignore_index\": [\n",
       "        null,\n",
       "        null\n",
       "    ],\n",
       "    \"gep_flank_window\": 4,\n",
       "    \"gep_parallel_embedding\": false,\n",
       "    \"gep_gradient_checkpoint\": false,\n",
       "    \"gep_zero_inflation\": false,\n",
       "    \"prompt_kind\": \"cistrome\",\n",
       "    \"prompt_dim_external\": 512,\n",
       "    \"dnabert2_ckpt\": null\n",
       "}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We use the `gep` preset model config and also set the `gep_flank_window` parameter to four.\n",
    "\n",
    "model_config = chrombert.get_preset_model_config(\"gep\",gep_flank_window=4)\n",
    "model_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "use organisim hg38; max sequence length is 6391\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/shared/chenqianqian/data_copy1/chenqianqian/finetune/test_model/ChromBERT_public_2/chrombert/base/model.py:56: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  ck = torch.load(ckpt_path, map_location=torch.device('cpu'))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "=====================================================================================\n",
       "Layer (type:depth-idx)                                       Param #\n",
       "=====================================================================================\n",
       "ChromBERTGEP                                                 --\n",
       "├─PoolFlankWindow: 1-1                                       --\n",
       "│    └─ChromBERT: 2-1                                        --\n",
       "│    │    └─BERTEmbedding: 3-1                               (4,916,736)\n",
       "│    │    └─ModuleList: 3-2                                  51,978,240\n",
       "├─GeneralHeader: 1-2                                         --\n",
       "│    └─CistromeEmbeddingManager: 2-2                         --\n",
       "│    └─Conv2d: 2-3                                           769\n",
       "│    └─ReLU: 2-4                                             --\n",
       "│    └─ResidualBlock: 2-5                                    --\n",
       "│    │    └─Linear: 3-3                                      1,099,776\n",
       "│    │    └─Linear: 3-4                                      1,049,600\n",
       "│    │    └─LayerNorm: 3-5                                   2,048\n",
       "│    │    └─Linear: 3-6                                      1,099,776\n",
       "│    │    └─Dropout: 3-7                                     --\n",
       "│    └─ResidualBlock: 2-6                                    --\n",
       "│    │    └─Linear: 3-8                                      787,200\n",
       "│    │    └─Linear: 3-9                                      590,592\n",
       "│    │    └─LayerNorm: 3-10                                  1,536\n",
       "│    │    └─Linear: 3-11                                     787,200\n",
       "│    │    └─Dropout: 3-12                                    --\n",
       "│    └─ResidualBlock: 2-7                                    --\n",
       "│    │    └─Linear: 3-13                                     196,864\n",
       "│    │    └─Linear: 3-14                                     65,792\n",
       "│    │    └─LayerNorm: 3-15                                  512\n",
       "│    │    └─Linear: 3-16                                     196,864\n",
       "│    │    └─Dropout: 3-17                                    --\n",
       "│    └─Linear: 2-8                                           257\n",
       "=====================================================================================\n",
       "Total params: 62,773,762\n",
       "Trainable params: 18,873,346\n",
       "Non-trainable params: 43,900,416\n",
       "====================================================================================="
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = model_config.init_model()\n",
    "model.freeze_pretrain(2) ### freeze chrombert 6 transformer blocks during fine-tuning  \n",
    "summary(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configure training parameters and fine-tune  \n",
    "\n",
    "The model is fine-tuned using PyTorch Lightning with a straightforward parameter configuration. To save time, fine-tuning is performed on a smaller dataset.  \n",
    "\n",
    "*Note:* Due to the stochastic nature of the tuning process, results may vary. For improved performance, consider increasing the number of epochs and expanding the dataset size.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/chenqianqian/.conda/envs/flash23_torch20/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: Metric `SpearmanCorrcoef` will save all targets and predictions in the buffer. For large datasets, this may lead to large memory footprint.\n",
      "  warnings.warn(*args, **kwargs)  # noqa: B028\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "chrombert.finetune.train.pl_module.RegressionPLModule"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_config = chrombert.finetune.TrainConfig(\n",
    "    kind='regression',        \n",
    "    loss='rmse',\n",
    "    max_epochs=2,\n",
    "    accumulate_grad_batches=2,\n",
    "    val_check_interval=2,\n",
    "    limit_val_batches=10,\n",
    "    tag='gep',\n",
    "    checkpoint_mode='max',\n",
    "    checkpoint_metric='pcc'\n",
    "    )\n",
    "pl_module = train_config.init_pl_module(model) # wrap model with PyTorch Lightning module\n",
    "type(pl_module)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we start fine-tuning!      \n",
    "The trainer will save logs in a format compatible with TensorBoard, and the checkpoint with the lowest validation loss will be saved during the process.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using bfloat16 Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "You are using a CUDA device ('NVIDIA A100-PCIE-40GB') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "Missing logger folder: lightning_logs/gep\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "\n",
      "  | Name  | Type         | Params | Mode \n",
      "-----------------------------------------------\n",
      "0 | model | ChromBERTGEP | 62.8 M | train\n",
      "-----------------------------------------------\n",
      "18.9 M    Trainable params\n",
      "43.9 M    Non-trainable params\n",
      "62.8 M    Total params\n",
      "251.095   Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "155c33a99aa44289941a8a184dfa91f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/chenqianqian/.conda/envs/flash23_torch20/lib/python3.9/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:475: Your `val_dataloader`'s sampler has shuffling enabled, it is strongly recommended that you turn shuffling off for val/test dataloaders.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e39ec60076f4ee7b425e669d5525b98",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "41108d87fbfc4f8ca7ec7913d3466dbf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "abd8f5abc07f40e68abd9f5112f442e1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "583b633d45764c0991c037088df29a15",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "caa090d1c5f14555ba802f1fdabe2c8d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ca87e2ceb7134ba0959d08e955bb7ef2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "73a2b57d475d401d919be5a45b2b244f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d34081f52a4b4bd6815cb9ecb58f6fdb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4d1240c9f9e245ea81c713b959296454",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b207c465e7944589a5ece8ca914397b2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cc8eeec16cb4417fa2e84bdebad82b88",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ddba935396004524bcd141b51c551bb5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cdba7fba78094c4e9f6eb1eb9b90dca9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eea7696b965d4fbe83370aeb55204517",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c7f24301d16a48b4b288b3154ccd48b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c3d0c7b4fdee472a9653ea3b3f5dea4c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1dad1d895f464b0b8249d128fdbad42b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0567c59e04e247e0908d53578f174fd7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6ddf78c4ebe246b5833b21c891624f1e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "912065f8f6b944b59df864323a5f01a9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5e5b5df794ca4b538105f0f7126c2351",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aa1d6d532a3744fb924e3becef4f06ed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d9758072b1584c329c228d635ee53e4b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0546a84773ef4db287ebd032d27b25ee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ed047a279eec4f71870a06abf84e84ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "45fc96aac22d4920923713d0672e7a0a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c13ae8c2d5f24346ba00a534773c830e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3292c74bb17d4d5cb99621dfeb695ea9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a1d0694e5ee4a2ebb25700dc2225c1c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4504e81325b54dc998fb079b74ebecdc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a223e04229c0462fa366332aa9b42a21",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4dcb144f0b00489a88a713668f3fdcd0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d5417c7d1f654c23a04b3d1d79f00262",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a24b2a6d6c0e4b5d9d8699877eb7999e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c92701a6d71a4b44b23253f17fb7e2cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c8b0a9fdae83416a88355dc5d9552373",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f5d6af52ebb846ebab1badcacaf1fa2c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8131da69a3814a20893010a91f189c50",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "71ad2adaa322458c9b7b9fc38cb7e90f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f1ba598031e44499a255cad3f16b55fe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f0ea22a48e545ae803d050dd3082b10",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=2` reached.\n"
     ]
    }
   ],
   "source": [
    "callback_ckpt = pl.callbacks.ModelCheckpoint(monitor = f\"{train_config.tag}_validation/{train_config.loss}\", mode = \"min\")\n",
    "trainer = pl.Trainer(\n",
    "    max_epochs=train_config.max_epochs,\n",
    "    log_every_n_steps=1, \n",
    "    limit_val_batches = train_config.limit_val_batches,\n",
    "    val_check_interval = train_config.val_check_interval,\n",
    "    accelerator=\"gpu\", \n",
    "    accumulate_grad_batches= train_config.accumulate_grad_batches, \n",
    "    fast_dev_run=False, \n",
    "    precision=\"bf16-mixed\",\n",
    "    strategy=\"auto\",\n",
    "    callbacks=[\n",
    "        pl.callbacks.LearningRateMonitor(),\n",
    "        callback_ckpt,   \n",
    "    ],\n",
    "    logger=pl.loggers.TensorBoardLogger(\"lightning_logs\", name='gep'))\n",
    "trainer.fit(pl_module,data_module)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Evaluate the fine-tuned model  \n",
    "\n",
    "ChromBERT has been successfully fine-tuned! You can evaluate the model directly using `pl_module.model`. However, note that due to flash-attention settings, the dropout probability cannot be adjusted by `model.eval()`, which may introduce some randomness to the output.  \n",
    "\n",
    "So, to ensure consistent results,it's suggested to save the fine-tuned checkpoint and reload it into the original model configuration for accurate evaluation.  \n",
    "\n",
    "In addition, we use only downsampled test data for evaluation in this tutorial to save time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate the model fine-tuned with limited data\n",
    "\n",
    "We first load the fine-tuned model and evaluate it on the downsampled test data here.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "update path: mtx_mask = config/hg38_6k_mask_matrix.tsv\n",
      "update path: pretrain_ckpt = checkpoint/hg38_6k_1kb_pretrain.ckpt\n",
      "use organisim hg38; max sequence length is 6391\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/shared/chenqianqian/data_copy1/chenqianqian/finetune/test_model/ChromBERT_public_2/chrombert/base/model.py:56: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  ck = torch.load(ckpt_path, map_location=torch.device('cpu'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading checkpoint from /shared/chenqianqian/data_copy1/chenqianqian/finetune/test_model/ChromBERT_public_2/examples/tutorials/lightning_logs/gep/version_0/checkpoints/epoch=0-step=2.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/shared/chenqianqian/data_copy1/chenqianqian/finetune/test_model/ChromBERT_public_2/chrombert/finetune/model/basic_model.py:49: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  new_state = torch.load(ckpt)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading from pl module, remove prefix 'model.'\n",
      "Loaded 110/110 parameters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:23<00:00,  1.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'pearsonr': tensor(-0.0272), 'spearmanr': tensor(0.0601), 'mse': tensor(0.5545), 'mae': tensor(0.5203), 'r2': tensor(-0.1555)}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "/home/chenqianqian/.conda/envs/flash23_torch20/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: Metric `SpearmanCorrcoef` will save all targets and predictions in the buffer. For large datasets, this may lead to large memory footprint.\n",
      "  warnings.warn(*args, **kwargs)  # noqa: B028\n"
     ]
    }
   ],
   "source": [
    "gep_ft_ckpt = os.path.abspath(glob.glob('./lightning_logs/gep/version*/checkpoints/*.ckpt')[0])\n",
    "model_config = chrombert.get_preset_model_config(\"gep\",gep_flank_window=4, dropout=0)\n",
    "ft_model = model_config.init_model(finetune_ckpt = gep_ft_ckpt)\n",
    "\n",
    "dl = data_module.test_dataloader()\n",
    "ft_model.cuda()\n",
    "\n",
    "with torch.no_grad():\n",
    "    y_preds = []\n",
    "    y_labels = []\n",
    "    for idx, batch in enumerate(tqdm(dl, total=len(dl))):\n",
    "        for k in batch:\n",
    "            if isinstance(batch[k], torch.Tensor):\n",
    "                batch[k] = batch[k].cuda()\n",
    "        y_pred = ft_model(batch).cpu()\n",
    "        y_label = batch['label'].cpu()\n",
    "        y_preds.append(y_pred)\n",
    "        y_labels.append(y_label)\n",
    "    y_preds = torch.cat(y_preds)\n",
    "    y_labels = torch.cat(y_labels)\n",
    "predicts = y_preds.view(-1)\n",
    "labels = y_labels.view(-1)\n",
    "metrics_pearsonr = tm.PearsonCorrCoef()\n",
    "metrics_spearmanr = tm.SpearmanCorrCoef()\n",
    "metrics_mse = tm.MeanSquaredError()\n",
    "metrics_mae = tm.MeanAbsoluteError()\n",
    "metrics_r2 = tm.R2Score()\n",
    "score_pearsonr = metrics_pearsonr(predicts, labels)\n",
    "score_spearmanr = metrics_spearmanr(predicts, labels)\n",
    "score_mse = metrics_mse(predicts, labels)\n",
    "score_mae = metrics_mae(predicts, labels)\n",
    "score_r2 = metrics_r2(predicts, labels)\n",
    "scores = {\n",
    "    \"pearsonr\": score_pearsonr,\n",
    "    \"spearmanr\": score_spearmanr,\n",
    "    \"mse\": score_mse,\n",
    "    \"mae\": score_mae,\n",
    "    \"r2\": score_r2,\n",
    "    }\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performance of the Fine-Tuned Model  \n",
    "\n",
    "The model fine-tuned with limited data demonstrated suboptimal performance during evaluation. To address this, we provided a checkpoint fine-tuned on the entire dataset and will evaluate its performance here.  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "update path: mtx_mask = config/hg38_6k_mask_matrix.tsv\n",
      "update path: pretrain_ckpt = checkpoint/hg38_6k_1kb_pretrain.ckpt\n",
      "use organisim hg38; max sequence length is 6391\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/shared/chenqianqian/data_copy1/chenqianqian/finetune/test_model/ChromBERT_public_2/chrombert/base/model.py:56: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  ck = torch.load(ckpt_path, map_location=torch.device('cpu'))\n",
      "/shared/chenqianqian/data_copy1/chenqianqian/finetune/test_model/ChromBERT_public_2/chrombert/finetune/model/basic_model.py:49: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  new_state = torch.load(ckpt)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading checkpoint from /home/chenqianqian/.cache/chrombert/data/demo/transdifferentiation/transcriptome/gep_fibroblast_to_myoblast.ckpt\n",
      "Loading from pl module, remove prefix 'model.'\n",
      "Loaded 110/110 parameters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:23<00:00,  1.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'pearsonr': tensor(0.7469), 'spearmanr': tensor(0.5639), 'mse': tensor(0.2352), 'mae': tensor(0.3242), 'r2': tensor(0.5099)}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "/home/chenqianqian/.conda/envs/flash23_torch20/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: Metric `SpearmanCorrcoef` will save all targets and predictions in the buffer. For large datasets, this may lead to large memory footprint.\n",
      "  warnings.warn(*args, **kwargs)  # noqa: B028\n"
     ]
    }
   ],
   "source": [
    "gep_ft_ckpt = f'{gep_dir}/gep_fibroblast_to_myoblast.ckpt'\n",
    "model_config = chrombert.get_preset_model_config(\"gep\",gep_flank_window=4, dropout=0)\n",
    "ft_model = model_config.init_model(finetune_ckpt = gep_ft_ckpt)\n",
    "\n",
    "dl = data_module.test_dataloader()\n",
    "ft_model.cuda()\n",
    "\n",
    "with torch.no_grad():\n",
    "    y_preds = []\n",
    "    y_labels = []\n",
    "    for batch in tqdm(dl,total=len(dl)):\n",
    "        for k in batch:\n",
    "            if isinstance(batch[k], torch.Tensor):\n",
    "                batch[k] = batch[k].cuda()\n",
    "        y_pred = ft_model(batch).cpu()\n",
    "        y_label = batch['label'].cpu()\n",
    "        y_preds.append(y_pred)\n",
    "        y_labels.append(y_label)\n",
    "    y_preds = torch.cat(y_preds)\n",
    "    y_labels = torch.cat(y_labels)\n",
    "predicts = y_preds.view(-1)\n",
    "labels = y_labels.view(-1)\n",
    "metrics_pearsonr = tm.PearsonCorrCoef()\n",
    "metrics_spearmanr = tm.SpearmanCorrCoef()\n",
    "metrics_mse = tm.MeanSquaredError()\n",
    "metrics_mae = tm.MeanAbsoluteError()\n",
    "metrics_r2 = tm.R2Score()\n",
    "score_pearsonr = metrics_pearsonr(predicts, labels)\n",
    "score_spearmanr = metrics_spearmanr(predicts, labels)\n",
    "score_mse = metrics_mse(predicts, labels)\n",
    "score_mae = metrics_mae(predicts, labels)\n",
    "score_r2 = metrics_r2(predicts, labels)\n",
    "scores = {\n",
    "    \"pearsonr\": score_pearsonr,\n",
    "    \"spearmanr\": score_spearmanr,\n",
    "    \"mse\": score_mse,\n",
    "    \"mae\": score_mae,\n",
    "    \"r2\": score_r2,\n",
    "    }\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Infer key regulators  \n",
    "\n",
    "Using the fine-tuned model, we analyze embedding similarities between upregulated and unchanged genomic regions. Lower embedding similarity is hypothesized to indicate a greater functional shift, highlighting the potential role of key regulators in cell state transitions.  \n",
    "\n",
    "To save time, we perform the analysis on a downsampled set of upregulated and unchanged genomic regions.  \n",
    "\n",
    "*Note:* Only the selected factors are considered for this analysis, excluding histone modifications and chromatin accessibility.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "update path: mtx_mask = config/hg38_6k_mask_matrix.tsv\n",
      "update path: pretrain_ckpt = checkpoint/hg38_6k_1kb_pretrain.ckpt\n",
      "update path: finetune_ckpt = /home/chenqianqian/.cache/chrombert/data/demo/transdifferentiation/transcriptome/gep_fibroblast_to_myoblast.ckpt\n",
      "use organisim hg38; max sequence length is 6391\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/shared/chenqianqian/data_copy1/chenqianqian/finetune/test_model/ChromBERT_public_2/chrombert/base/model.py:56: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  ck = torch.load(ckpt_path, map_location=torch.device('cpu'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading checkpoint from /home/chenqianqian/.cache/chrombert/data/demo/transdifferentiation/transcriptome/gep_fibroblast_to_myoblast.ckpt\n",
      "Loading from pl module, remove prefix 'model.'\n",
      "Loaded 110/110 parameters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/shared/chenqianqian/data_copy1/chenqianqian/finetune/test_model/ChromBERT_public_2/chrombert/finetune/model/basic_model.py:49: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  new_state = torch.load(ckpt)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "=====================================================================================\n",
       "Layer (type:depth-idx)                                       Param #\n",
       "=====================================================================================\n",
       "ChromBERTEmbedding                                           --\n",
       "├─PoolFlankWindow: 1-1                                       --\n",
       "│    └─ChromBERT: 2-1                                        --\n",
       "│    │    └─BERTEmbedding: 3-1                               4,916,736\n",
       "│    │    └─ModuleList: 3-2                                  51,978,240\n",
       "├─CistromeEmbeddingManager: 1-2                              --\n",
       "=====================================================================================\n",
       "Total params: 56,894,976\n",
       "Trainable params: 56,894,976\n",
       "Non-trainable params: 0\n",
       "====================================================================================="
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the fine-tuned model\n",
    "model_tuned = chrombert.get_preset_model_config(\n",
    "    \"gep\", \n",
    "    gep_flank_window = 4,\n",
    "    dropout = 0,\n",
    "    finetune_ckpt = f'{gep_dir}/gep_fibroblast_to_myoblast.ckpt').init_model() # use absolute path here, to avoid mixing of preset\n",
    "# Get the embedding manager\n",
    "model_emb = model_tuned.get_embedding_manager().cuda()\n",
    "summary(model_emb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gather regulator embeddings in upregulated gene"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "update path: hdf5_file = hg38_6k_1kb.hdf5\n",
      "update path: meta_file = config/hg38_6k_meta.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:43<00:00, 10.95s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([100, 1073, 768])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_config = chrombert.get_preset_dataset_config(\"multi_flank_window\",supervised_file = f'{gep_dir}/up_data_sample.csv', batch_size = 32, num_workers = 4)\n",
    "dl = dataset_config.init_dataloader()\n",
    "up_gep_embs = []\n",
    "for batch in tqdm(dl):\n",
    "    with torch.no_grad():\n",
    "        for k, v in batch.items():\n",
    "            if isinstance(v, torch.Tensor):\n",
    "                batch[k] = v.cuda()\n",
    "        emb = model_emb(batch).cpu()\n",
    "        up_gep_embs.append(emb)\n",
    "up_gep_embs = torch.cat(up_gep_embs)\n",
    "up_gep_embs.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gather regulator embeddings in unchanged genes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "update path: hdf5_file = hg38_6k_1kb.hdf5\n",
      "update path: meta_file = config/hg38_6k_meta.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:43<00:00, 10.98s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([100, 1073, 768])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_config = chrombert.get_preset_dataset_config(\"multi_flank_window\",supervised_file = f'{gep_dir}/nochange_data_sample.csv', batch_size = 32, num_workers = 4)\n",
    "dl = dataset_config.init_dataloader()\n",
    "nochange_gep_embs = []\n",
    "for batch in tqdm(dl):\n",
    "    with torch.no_grad():\n",
    "        for k, v in batch.items():\n",
    "            if isinstance(v, torch.Tensor):\n",
    "                batch[k] = v.cuda()\n",
    "        emb = model_emb(batch).cpu()\n",
    "        nochange_gep_embs.append(emb)\n",
    "nochange_gep_embs = torch.cat(nochange_gep_embs)\n",
    "nochange_gep_embs.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We consider only factors below, remove histone modifications and chromatin accessibility. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([991, 768]), torch.Size([991, 768]))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(os.path.join(base_dir, \"config\",\"hg38_6k_factors_list.txt\"),\"r\") as f:\n",
    "    factors = f.read().strip().split(\"\\n\")\n",
    "factors = [f.strip().lower() for f in factors]\n",
    "\n",
    "\n",
    "indices = np.in1d(model_emb.list_regulator,factors)\n",
    "names = np.array(model_emb.list_regulator)[indices]\n",
    "up_gep_embs = up_gep_embs.mean(axis=0)[indices]\n",
    "nochange_gep_embs = nochange_gep_embs.mean(axis=0)[indices]\n",
    "up_gep_embs.shape, nochange_gep_embs.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyze the embedding similarity between upregulated and unchanged genes\n",
    "\n",
    "We calculate the cosine similarity between the embeddings of upregulated and unchanged genomic regions to identify key regulators.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>factors</th>\n",
       "      <th>similarity</th>\n",
       "      <th>rank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>chd4</td>\n",
       "      <td>0.924975</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>esco2</td>\n",
       "      <td>0.935212</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>cbx7</td>\n",
       "      <td>0.946856</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>cbx6</td>\n",
       "      <td>0.946874</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>cbx8</td>\n",
       "      <td>0.949367</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>986</th>\n",
       "      <td>zbtb10</td>\n",
       "      <td>0.998598</td>\n",
       "      <td>987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>987</th>\n",
       "      <td>zbed4</td>\n",
       "      <td>0.998614</td>\n",
       "      <td>988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>988</th>\n",
       "      <td>nkx2-5</td>\n",
       "      <td>0.998627</td>\n",
       "      <td>989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>989</th>\n",
       "      <td>snapc4</td>\n",
       "      <td>0.998678</td>\n",
       "      <td>990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>990</th>\n",
       "      <td>dbp</td>\n",
       "      <td>0.998807</td>\n",
       "      <td>991</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>991 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    factors  similarity  rank\n",
       "0      chd4    0.924975     1\n",
       "1     esco2    0.935212     2\n",
       "2      cbx7    0.946856     3\n",
       "3      cbx6    0.946874     4\n",
       "4      cbx8    0.949367     5\n",
       "..      ...         ...   ...\n",
       "986  zbtb10    0.998598   987\n",
       "987   zbed4    0.998614   988\n",
       "988  nkx2-5    0.998627   989\n",
       "989  snapc4    0.998678   990\n",
       "990     dbp    0.998807   991\n",
       "\n",
       "[991 rows x 3 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "gep_similarity = [cosine_similarity(up_gep_embs[i].reshape(1, -1), nochange_gep_embs[i].reshape(1, -1))[0, 0] for i in range(up_gep_embs.shape[0])]\n",
    "gep_similarity_df = pd.DataFrame({'factors':names,'similarity':gep_similarity}).sort_values(by='similarity').reset_index(drop=True)\n",
    "gep_similarity_df['rank']=gep_similarity_df.index + 1\n",
    "gep_similarity_df.to_csv(f'{gep_dir}/gep_similarity_df.csv',index=False)\n",
    "gep_similarity_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['chd4',\n",
       " 'esco2',\n",
       " 'cbx7',\n",
       " 'cbx6',\n",
       " 'cbx8',\n",
       " 'brd7',\n",
       " 'hira',\n",
       " 'myf5',\n",
       " 'ring1',\n",
       " 'neurog2',\n",
       " 'kdm6b',\n",
       " 'ubn1',\n",
       " 'nr3c2',\n",
       " 'rpa2',\n",
       " 'sumo1',\n",
       " 'yap1',\n",
       " 'ptpn11',\n",
       " 'myod1',\n",
       " 'klf11',\n",
       " 'phf2',\n",
       " 'prkdc',\n",
       " 'brdu',\n",
       " 'ssrp1',\n",
       " 'tead',\n",
       " 'tead1']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indentified_factor = gep_similarity_df[gep_similarity_df['rank']<=25]['factors'].tolist()\n",
    "indentified_factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>factors</th>\n",
       "      <th>similarity</th>\n",
       "      <th>rank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>myod1</td>\n",
       "      <td>0.983192</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   factors  similarity  rank\n",
       "17   myod1    0.983192    18"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gep_similarity_df[gep_similarity_df['factors']=='myod1']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We identified 25 key regulators in the transcriptome, including the notable regulator 'MYOD1'."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combine the regulator rankings from both chromatin accessibility and transcriptome\n",
    "Final top 25 key regulators derived from average ranks across both chromatin accessibility and transcriptome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>factors</th>\n",
       "      <th>similarity_gep</th>\n",
       "      <th>rank_gep</th>\n",
       "      <th>similarity_chrom_acc</th>\n",
       "      <th>rank_chrom_acc</th>\n",
       "      <th>averge_rank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>myod1</td>\n",
       "      <td>0.983192</td>\n",
       "      <td>18</td>\n",
       "      <td>-0.064511</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   factors  similarity_gep  rank_gep  similarity_chrom_acc  rank_chrom_acc  \\\n",
       "17   myod1        0.983192        18             -0.064511               1   \n",
       "\n",
       "    averge_rank  \n",
       "17            2  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chrom_accessibility_path = f'{gep_dir}/../chrom_accessibility/chromatin_accessibility_similarity_df.csv'\n",
    "if not os.path.exists(chrom_accessibility_path):\n",
    "    raise ValueError(\"Please follow the tutorial for key regulators inference during cell state transition: Chromatin accessibility\")\n",
    "else:\n",
    "    chrom_acc_similarity_df = pd.read_csv(chrom_accessibility_path)\n",
    "    average_rank_df = pd.merge(gep_similarity_df, chrom_acc_similarity_df, on='factors', how='inner', suffixes=('_gep', '_chrom_acc'))\n",
    "    average_rank_df['averge_rank'] = ((average_rank_df['rank_gep']+average_rank_df['rank_chrom_acc'])/2).rank().astype(int)\n",
    "    average_rank_df=average_rank_df.sort_values(by='averge_rank')\n",
    "    average_rank_df\n",
    "    \n",
    "average_rank_df[average_rank_df['factors']=='myod1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['myf5',\n",
       " 'myod1',\n",
       " 'neurog2',\n",
       " 'yap1',\n",
       " 'nr3c2',\n",
       " 'tead1',\n",
       " 'tead',\n",
       " 'dux4',\n",
       " 'pgbd3',\n",
       " 'chd4',\n",
       " 'myog',\n",
       " 'hira',\n",
       " 'pax3-foxo1a',\n",
       " 'tbx5',\n",
       " 'nr3c1',\n",
       " 'snai2',\n",
       " 'ss18',\n",
       " 'prmt5',\n",
       " 'ubn1',\n",
       " 'rb1',\n",
       " 'six2',\n",
       " 'klf11',\n",
       " 'ercc6',\n",
       " 'sumo1',\n",
       " 'esco2']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_indentified_factor = average_rank_df[average_rank_df['averge_rank']<=25]['factors'].tolist()\n",
    "final_indentified_factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "demo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
